{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ddfbd9-42a8-4d79-9f54-d32ea0fe1cf1",
   "metadata": {},
   "source": [
    "# Day 2\n",
    "\n",
    "© 2026, Marcus D. Bloice, licensed under <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY-SA 4.0</a><img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\" alt=\"\" style=\"max-width: 1em;max-height:1em;margin-left: .2em;\"><img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\" alt=\"\" style=\"max-width: 1em;max-height:1em;margin-left: .2em;\"><img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg\" alt=\"\" style=\"max-width: 1em;max-height:1em;margin-left: .2em;\">\n",
    "\n",
    "## Topics\n",
    "\n",
    "Today we will cover the following topics:\n",
    "\n",
    "- The Pandas Library\n",
    "- The NumPy Library\n",
    "- SQL Databases\n",
    "- Plotting\n",
    "- Machine Learning\n",
    "- Assignment\n",
    "\n",
    "For data analysis, scientific programming, and machine learning the essential tools that you'll use are Pandas and NumPy. For plotting the most commonly used package is matplotlib, which we will cover also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9541efe-c26e-4e9a-af82-3b20342e9d05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Science Basics: Pandas and NumPy\n",
    "\n",
    "Now we will cover the basics of Data Science, as this is likely an area that is of interest to many of you attending this course. \n",
    "\n",
    "We will cover a few distinct packages in order to learn the basics of Data Science, namely:\n",
    "\n",
    "- Pandas\n",
    "- NumPy\n",
    "- MatPlotLib\n",
    "- SciKit-Learn\n",
    "- SQLite\n",
    "\n",
    "## Overview\n",
    "\n",
    "Let's first discuss each of these packages. \n",
    "\n",
    "### Pandas\n",
    "\n",
    "Pandas (≈ Python Data Analysis) is a data manipulation framework for Python. You can think if it as Excel for Python or Python's DataFrames from R. \n",
    "\n",
    "Pandas makes it easy to create and manipulate tabular data, and can read many file formats including Excel and CSV files, but also SPSS files and other formats.\n",
    "\n",
    "### NumPy\n",
    "\n",
    "NumPy is another Data Science toolkit that is used frequently. \n",
    "\n",
    "You can think of NumPy as a more lower-level toolkit for manipulating tabular data, and is more like MATLAB for Python.\n",
    "\n",
    "### MatPlotLib\n",
    "\n",
    "The most popular plotting library for Python is MatPlotLib, and we will cover the basics of it in this course. Plotting is more or less essential for exploratory data analysis. \n",
    "\n",
    "### SQLite and Databases\n",
    "\n",
    "If you are working with very large data, split across multiple tables and reltionships, you may well encounter data in database form. \n",
    "\n",
    "SQLite is one such database software that is used frequently.\n",
    "\n",
    "### SciKit-Learn\n",
    "\n",
    "SciKit-Learn is a Python package for Machine Learning. \n",
    "\n",
    "We will not cover much Machine Learning in this course, except for some basics. If you want to learn more about Machine Learning and Deep Learning, then take a look at our Advanced Topics in Scientific Programming course, more details can be found on my homepage: <https://user.medunigraz.at/marcus.bloice/>\n",
    "\n",
    "However, we will quickly cover some very basic algorimths such as Logistic Regression, so that you can see how SciKit-Learn works with data from packages such as NumPy or Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6def044-6a70-4796-906b-da1cc70aac50",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "As mentioned previously, Pandas is a library for tabular data. It provides the ability to analyse spreadsheet-like data in tabular form, not unlike Excel, or R's Data Frames.\n",
    "\n",
    "Python Pandas is used for data manipulation and analysis. Core purposes:\n",
    "\n",
    "- Structured data handling: Work with tabular and labeled data using DataFrame and Series.\n",
    "- Data loading and saving: Read/write CSV, Excel, JSON, SQL databases, Parquet, etc.\n",
    "- Data cleaning: Handle missing values, filter rows, select columns, convert data types, rename, reorder.\n",
    "- Data transformation: Grouping, aggregation, reshaping (pivot, melt), joining/merging datasets, sorting.\n",
    "- Exploratory data analysis: Summary statistics, distributions, correlations, quick inspection of datasets.\n",
    "- Time series analysis: Date/time indexing, resampling, rolling windows.\n",
    "- Feeds directly into NumPy, matplotlib, and scikit-learn workflows.\n",
    "\n",
    "In short, Pandas is the standard tool in Python for turning raw data into clean, analysable structures suitable for statistics, visualisation, and machine learning.\n",
    "\n",
    "In the machine learning or data analysis workflow what you will often find is that you will tend to load and clean and explore your data with Pandas first, and then use NumPy for the final stages of the work. We will look at NumPy later.\n",
    "\n",
    "To import Pandas, we will do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e4ef7-2111-4826-9a6c-0d77e07b97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416736f4-601e-47be-93c5-0db7b6f2dce7",
   "metadata": {},
   "source": [
    "We use here the `pd` convention—you will see this online all the time, and has become standard convetion for when importing Pandas, in order to save us some keystrokes.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Before we get to importing some data, let's create a small dataset so that we can test some of the functionality that is built in to Pandas.\n",
    "\n",
    "Let's start with the absolute basics: Pandas data structures are based on Series and Data Frames. \n",
    "\n",
    "- Series: 1-dimensional, like a list \n",
    "- Data Frame: 2-dimensional, tabular style data, like a spreadsheet\n",
    "\n",
    "We will concentrate almost entirely on 2D Data Frames, however first we will look at how to create a 1D Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b9ea7-e7ed-41b1-9c73-f34649fcb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([10, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01a335-dfe7-434d-8060-07c1f2858349",
   "metadata": {},
   "outputs": [],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f27ee7-e9d2-407a-b3b1-5e14fb73ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2a2f2-c832-4aa7-a0eb-36f9b13fc0c4",
   "metadata": {},
   "source": [
    "Unlike a standard Python list, a series can have an index, which can be non-numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1407c36-f39d-4cf6-832e-761dd83b08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([10, 20, 30], index=['Value 1', 'Value 2', 'Value 3'])\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd033b2d-c421-453c-8238-62d41c05b2aa",
   "metadata": {},
   "source": [
    "However, mostly you will be working with 2D, tabular data. For this we use a Data Frame. \n",
    "\n",
    "To do this, you create a new data set using the `DataFrame()` function. You can do this by passing some data to it and you will get a new Data Frame out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e7fb5-353e-454f-bd4d-1e327019791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.DataFrame({\n",
    "    'age': [25, 32, 41],\n",
    "    'height': [175, 180, 168]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc2410-3428-412a-b2af-06a49ce38e59",
   "metadata": {},
   "source": [
    "We create a 2D data frame **by column** - each column is defined using a list. Notice how we are also able to name these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cfa34-9fa0-4b4e-b050-f2c29375823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a1dd21-c76d-41e3-9df4-eb7daaab9093",
   "metadata": {},
   "source": [
    "So Data Frames "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e5764-1109-453f-be55-30139d43ae6f",
   "metadata": {},
   "source": [
    "You can see we have got 2 columns, named `age` and `height` and 3 rows, which has automaticallly been given a numerical index.\n",
    "\n",
    "A numerical, 0-based index is often exactly what you want, however we may want to have a custom index. We do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b62916-be82-4d42-96f1-716ad8c82c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.DataFrame({\n",
    "    'age': [25, 32, 41],\n",
    "    'height': [175, 180, 168]}, \n",
    "    index = ['patient_id_1', 'patient_id_2', 'patient_id_3'])\n",
    "\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f270a-33ab-4a20-a271-fda450f84427",
   "metadata": {},
   "source": [
    "Ok let's now create a Data Frame with a few columns, with various types of data.\n",
    "\n",
    "You may have noticed, that we passed our data to the `DataFrame()` function as a dictionary, that is how we were able to name each of the columns. \n",
    "\n",
    "Therefore, if you have you data as a dictionary, you can just pass this to `DataFrame()` and it will create a Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87740c1b-01c4-4ee9-8431-ddeadf0c056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"patient_id\": [\"P001\", \"P002\", \"P003\", \"P004\"],\n",
    "    \"age\": [45, 62, 51, 38],\n",
    "    \"sex\": [\"F\", \"M\", \"F\", \"M\"],\n",
    "    \"hba1c\": [6.1, 7.4, 5.9, 8.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa562f8-23a9-4c77-b18d-1a1fe84b10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0993509-dd0e-4f1c-b11b-a2ee7e96068a",
   "metadata": {},
   "source": [
    "Now, we pass the `data` dictionary to the `DataFrame()` and store the Data Frame in a variable called `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb5c57-094e-4550-aa6b-e02648905fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00529c0a-7567-41d6-b3f3-c503979c5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa354fe-cda9-4e17-9f2b-280988c9adee",
   "metadata": {},
   "source": [
    "As you can see, Jupyter does a good job previewing our data. However, the dataset above is very small. \n",
    "\n",
    "## Inspecting a Data Frame\n",
    "\n",
    "If you are dealing with very large datasets, you do not neccessarily want them to clog up your notebook with hundreds of rows. For that there are a few functions that can help us preview the data and get an overview of your data.\n",
    "\n",
    "A few useful functions can be used, such as:\n",
    "\n",
    "- `head()` / `tail()`\n",
    "- `info()`\n",
    "- `describe()`\n",
    "\n",
    "Let's try them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c141fbf-bd74-4330-907f-23f19298c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529c36e-5a64-4640-a85d-bc598c2a08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de41d2-4df2-4424-8d0a-868c5341903c",
   "metadata": {},
   "source": [
    "This normally only shows the first `n` rows, which defaults to `n=10`. This is useful to preview large datasets. In this case, as we only have 3 rows, it shows the entire database. The equivalent function is `tail(n)` which shows the last `n` rows of the Data Frame. \n",
    "\n",
    "Now try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e18a3-410b-4919-977a-a5555128bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828633c-c343-4c1d-934d-758710c4363e",
   "metadata": {},
   "source": [
    "Here we see various details about each column's type for example. We see that `age` is of type `int64`. While `hba1c` is of type `float64`. These types have been automatically inferred by Pandas when we first created the Data Frame.\n",
    "\n",
    "These types can of course be user-defined, which we won't cover.\n",
    "\n",
    "Last, we can try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2e746-73fc-42b5-8265-3fbff63089a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cab34c-05d9-41c2-84ee-aa75a505d788",
   "metadata": {},
   "source": [
    "Here we see some statistics regarding each of the numerical columns. Notice that for example the `patient_id` column doesn't appear here as this column is not numeric, and therefore values such as standard deviation would make no sense. So only suitable columns are shown when `desribe()` is used.\n",
    "\n",
    "To examine the number of rows and columns, there are a few properties we can examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6505ad4-24a1-48ad-9545-3110a2be71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patients.shape)\n",
    "print(patients.columns)\n",
    "print(patients.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a3478-e142-4914-9e5b-426707fb51b3",
   "metadata": {},
   "source": [
    "## Saving Data\n",
    "\n",
    "Later, we will see how we can open CSV files, Excel files, and so on. \n",
    "\n",
    "For now, let's see how you can save your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0447e-9818-470d-8ca1-11f2dbe26dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.to_csv(\"out.csv\", index=False)\n",
    "patients.to_excel(\"out.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab036e-026a-4ed6-b94c-091e0934d106",
   "metadata": {},
   "source": [
    "We can preview the CSV file directly with Jupyter, to view the Excel file, we need to download it first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174612e-f3f5-43df-94e0-264231117e0b",
   "metadata": {},
   "source": [
    "## Column Access\n",
    "\n",
    "Ok so we have our data in the Data Frame called `patients`, how do we access columns, rows, etc?\n",
    "\n",
    "Just as in lists, we use square brackets (`[`, `]`) for this.\n",
    "\n",
    "For example, let's say we wanted the `age` column and nothing else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74137104-5c71-469f-a063-a5bb1a162cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e5a5c2-7d85-49d2-b987-1260768a764a",
   "metadata": {},
   "source": [
    "This selects the `age` column, which can then be used further. **Note** that single columns are in fact Series.\n",
    "\n",
    "By accessing a single column, we can perform operations on the columns, such as getting the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31dd85-a255-4225-b03b-f61edf2b0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "mean(patients['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873ec36-2d96-4e74-b915-cb0379aabc29",
   "metadata": {},
   "source": [
    "Multiple columns can also be accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802e31b-504d-449b-b483-e04f2dc3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[['age', 'hba1c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995dbef5-49b1-4103-8a9a-4e4d763a5528",
   "metadata": {},
   "source": [
    "This time we have passed a list of column names, `['age', 'hba1c']` as an index.\n",
    "\n",
    "Another way to access individual columns is with the `.` notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b91ca-24be-4159-b0c8-a34d97e4880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['hba1c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e06e7b9-1743-4369-a073-e5bda9155e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.hba1c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4cf2a-e2ee-48b6-8f6d-cc5ac2221974",
   "metadata": {},
   "source": [
    "**Note**: for this to work, the column name cannot contain a space. If you want to use this shorthand notation, ensure you name your columns accordingly! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcab97-5a10-4018-b28f-fd99f6c1bc61",
   "metadata": {},
   "source": [
    "## Creating Columns\n",
    "\n",
    "Columns can be added using assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e03ab-c6b2-4324-8cce-de9bd39d4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['height'] = [167, 175, 165, 190]\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc51da5-2b1a-483d-8cf3-faad5b879eb9",
   "metadata": {},
   "source": [
    "Here we have created a `height` column and assigned it its values using a list. \n",
    "\n",
    "Let's also make a column for the patients' weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709d789-e4fe-4eb7-8079-180cd904253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['weight'] = [85, 70, 75, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f878be-7393-4d7f-9688-f6bda879495c",
   "metadata": {},
   "source": [
    "You can get creative with this, for example you can create a new row based on the data from another row or rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92a006-0073-4a5c-969e-54abf8fadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91545a2-0b9c-4eda-a726-42f6f6ef1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['bmi'] = patients['weight'] / (patients['height'] / 100) ** 2\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6047c61-c780-41f3-8359-aabb021c8156",
   "metadata": {},
   "source": [
    "## Row Access\n",
    "\n",
    "To access individual individual rows and columns, use the `loc` indexer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ea86e-4a38-4e39-9686-8130edded94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507dafc8-e59d-4678-8c6e-70cd7c31f30d",
   "metadata": {},
   "source": [
    "As you can see, we have recieved the row labelled `0` back. \n",
    "\n",
    "If we only want a specfic column, we can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347aa93-1ead-421f-86bc-a628ba12cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[0, 'sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477fe80-9db7-4867-a4e9-245af79451b7",
   "metadata": {},
   "source": [
    "Or more column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc200f9-8deb-4ac3-9635-72a91db3736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[0, ['sex', 'hba1c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f72d0b-6124-4312-a517-185bff8972ba",
   "metadata": {},
   "source": [
    "Therefore, `loc` expects you to provide which rows you want, followed by which columns (you will get all back by default).\n",
    "\n",
    "And we can of course use ranges for our indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91648a19-3f5f-44b5-9a30-2fa848146316",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf24df-cd80-4101-a2bf-4f2586416f4e",
   "metadata": {},
   "source": [
    "Notice that `loc` is start and stop **inclusive**.\n",
    "\n",
    "You can use `:` as shorthand for \"all rows\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f492f8f-9fdc-4b02-b55a-afba5952a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[:, ['age', 'height']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c80857-1d35-4c04-956c-b841635eb2a3",
   "metadata": {},
   "source": [
    "Notice that we passed the columns we wanted using their names. If you want purely index based access, use `iloc`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d9b1a-a4c4-441e-8022-dd10388c0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73d873-d8fa-472a-8acc-74e2c47ad685",
   "metadata": {},
   "source": [
    "Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604432e-72ff-4abe-9d4a-589e070de64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.iloc[:, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18095c-6e33-46fa-934c-01f47fb44551",
   "metadata": {},
   "source": [
    "Note that `iloc` is start **inslusive** and stop **exclusive**!\n",
    "\n",
    "- You can think of `iloc` as being numeric based access **only**. \n",
    "- If you want to be able to select rows and columns using their labels, use `loc`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849f394-a2b7-438f-89c9-ca3338d5b9b6",
   "metadata": {},
   "source": [
    "## Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad191c62-6ce0-4173-870e-c9dc6c1d2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = patients.drop('patient_id', axis=1)\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8a13d-8c6e-4fa6-8140-c872245adef9",
   "metadata": {},
   "source": [
    "Rows can be dropped by changing the axis to `\n",
    "\n",
    "- Axis 1: always refers to columns\n",
    "- Axis 0: always refers to rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377abd52-3110-485c-827a-541d2f5a2431",
   "metadata": {},
   "source": [
    "## Conditional Access\n",
    "\n",
    "Pandas lets you use logic in order to select rows. \n",
    "\n",
    "For example, we want to selec tonly patients with a BMI of over 25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4da9f-1bdb-43e8-85e6-8859a0c745ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['bmi'] > 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db2d7a-2faf-4ab0-a0af-9ab29521c234",
   "metadata": {},
   "source": [
    "What we get back is actually a index of true/false values depending on whether the condition was met.\n",
    "\n",
    "To get the data itself, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1210169-79eb-4c1b-8ac8-e78ac2d2b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[patients['bmi'] > 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83cfd6-46bc-4ecd-a606-fb4308e52f98",
   "metadata": {},
   "source": [
    "Here, we have accessed the rows of patients based on the condition. \n",
    "\n",
    "We can create a new column based on this condition. We saw above we can create a new column using assignment, we can create a new `diabetes` column based on the result of the conditional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f761a-1e86-4c85-a3c8-45efd75bba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['diabetes'] = patients['hba1c'] > 6\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c899bb4-233c-4377-ac1d-de3ca8366c41",
   "metadata": {},
   "source": [
    "### Advanced Indexing with `loc`\n",
    "\n",
    "You can do even more advanced indexing using `loc[]`, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b118828-4146-4e53-8f95-8b69da8a1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[\n",
    "    (patients[\"sex\"] == \"F\") & (patients[\"hba1c\"] > 5.0),  # Here is our index for loc\n",
    "    [\"age\", \"hba1c\", 'diabetes']                           # Here are the columns we want  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca83a23-996f-43d9-987b-73eece32150e",
   "metadata": {},
   "source": [
    "Using `loc` we can first provide the index logic, so for example that want `sex` to be `F` **and** `hba1c` to be greater than 5.0. Next, we provide the columns we want to select. In the example above we said we wanted only the `age` and `hba1c` columns.\n",
    "\n",
    "We could easily leave out the column index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e35994d-1387-47ff-9716-926406c70ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.loc[\n",
    "    (patients[\"sex\"] == \"F\") & (patients[\"hba1c\"] > 5.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c32b3-6a83-4fe1-a219-c426b11d1d2f",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Pandas has useful tools for finding and handling missing data. Real world datasets that you will work on often have missing data. \n",
    "\n",
    "Many data analysis algorithms will actually fail on data with missing values, so missing data almost always needs to be addressed.\n",
    "\n",
    "Let's add a column with some missing data so we can see its features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0369d7a1-a6b4-45af-90b7-2af35ee10e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919df3e3-7e43-4ccc-96ff-1005ddded22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "patients['lab_value'] = [10.1, 11.1, np.nan, 9.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd75fc-9549-4227-b875-6e190a245cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1e535-2b8b-4912-89f9-879776a636f1",
   "metadata": {},
   "source": [
    "Here we used a `np.nan` to create what is known as \"not a number\": NaN. \n",
    "\n",
    "NaN is a special value that corresponds to missing data. It is not written as 0, as this can be interpreted incorrectly. \n",
    "\n",
    "When importing data, Pandas will use NaN for values that are missing. \n",
    "\n",
    "Now we can search for missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20202c52-3787-4bbe-ba66-0fa9abfe87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b5942-cfb9-4f47-91ef-8fac15742e8b",
   "metadata": {},
   "source": [
    "Here we get a table back of `True`/`False` values, where we see our missing data. This is not much use on its own \n",
    "\n",
    "We can get an easier representation to read using `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e9d5d-2d89-4565-9f03-065035907aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa256d-cee3-4b0a-8b6c-a9a02815c77e",
   "metadata": {},
   "source": [
    "If we sum this, then we get all missing values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88609c5-afec-4956-a4e1-0e1dc21c0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4d490-5ad5-40ed-9848-9cb995da60bf",
   "metadata": {},
   "source": [
    "How do we handle missing data? \n",
    "\n",
    "We can do something very rudimentary like saying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488411d3-c1a0-40b9-82f5-61b334430aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161817e-82f9-4c3e-a85a-ac5134abf364",
   "metadata": {},
   "source": [
    "This uses the function `fillna()` to simply replace every value with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101d3ae-2a86-420d-8577-3567ac9b2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5ccc8-30b1-4f31-8c19-124162850cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bdc98-cbd8-4579-9716-7b0c3bc5f6a0",
   "metadata": {},
   "source": [
    "The row with the missing data has now been removed. \n",
    "\n",
    "While this works, in the sense that algorithms that cannot handle missing data will not fail, but it is not very sophisticated.\n",
    "\n",
    "We can replace the row with the missing data with the mean of the column, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572878a-14cd-4f8c-9986-a06ca741332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['lab_value'] = patients['lab_value'].fillna(patients['lab_value'].mean())\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b35cb-096c-4717-90c6-1ebf0ac7bc39",
   "metadata": {},
   "source": [
    "Now we have a reasonable value in place of our missing data. Note that mean is not the only option, you could take the median, mode (for categorical data), or even use some kind of regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99a6fb2-33ea-42f7-b6db-b5214082e844",
   "metadata": {},
   "source": [
    "## Copies\n",
    "\n",
    "You may have noticed something about the code snippets above. \n",
    "\n",
    "When we ran the code: \n",
    "\n",
    "```python\n",
    "patients.dropna()\n",
    "```\n",
    "\n",
    "It dropped the row with the missing value, but if you were to look at `patients` again, the row would still be there!\n",
    "\n",
    "This is because many functions in Pandas will return a **copy** of your data. This is more or less a safety feature. \n",
    "\n",
    "What you need to do with functions that return a copy is something like the following:\n",
    "\n",
    "```python\n",
    "patients = patients.dropna()\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "patients_no_nans = patients.dropna()\n",
    "```\n",
    "\n",
    "Now you have your original data, as it looked before `dropna()` was called, and a new Data Frame called `patients_no_nans` with the dropped row. \n",
    "\n",
    "Just be aware of this, as **many**, if not **most** Pandas functions returns copies of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812204a-0d91-44d1-ba06-2c9d259472a7",
   "metadata": {},
   "source": [
    "## Grouping/Aggregation \n",
    "\n",
    "Grouping data is a useful technique you may know from Excel, etc. and this can be done using `groupby()` in Pandas.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97993de6-8f15-4206-905a-b84204a05764",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.groupby('sex')['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bf19e-54d9-488b-bdf4-2669e305bf39",
   "metadata": {},
   "source": [
    "What is happening here is the following:\n",
    "\n",
    "1. `df.groupby('sex')`\n",
    "    - Splits the DataFrame into groups based on unique values in column `sex`\n",
    "    - In our case, we have 'M' and 'F'\n",
    "2. `['age']`\n",
    "    - Selects one column (`age`) from each group \n",
    "3. `.mean()`\n",
    "    - Computes the mean of age within each group \n",
    "\n",
    "In English: For each sex, compute the average age.\n",
    "\n",
    "Or combine it with the aggregate function `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3ac4d-e98f-4d85-8f06-374d528bf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.groupby('sex').agg({\n",
    "    'age': 'mean',\n",
    "    'height': ['mean', 'std']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb527fa-fc89-4dc2-aef4-8c0b00c48168",
   "metadata": {},
   "source": [
    "So what is happening here:\n",
    "\n",
    "1. `df.groupby('sex')`\n",
    "    - Same grouping as before\n",
    "2. `.agg({...})`\n",
    "    - Applies different aggregation functions to different columns\n",
    "    - This is passed as a dictionary:\n",
    "\n",
    "```python\n",
    "{\n",
    "  'age': 'mean',\n",
    "  'height': ['mean', 'std']\n",
    "}\n",
    "```\n",
    "\n",
    "- So for `age` compute the mean. \n",
    "- For `height` compute the mean and standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da72306-e2e5-4366-b4f4-caa2e5fa71da",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "\n",
    "If at any time you need your data as just standard lists, then you can use the `values` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bb70b-09de-426d-a4d2-3a30e62b225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017a9fc-7860-4faa-b9b9-e3fc85829a8e",
   "metadata": {},
   "source": [
    "These are just standard Python lists and can be used by any other Python code that handles lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f7dd9f-7a82-4bd7-9eec-d5928486fff1",
   "metadata": {},
   "source": [
    "## Orient\n",
    "\n",
    "Pandas has a function called `to_dict()`, which converts Data Frames to dictionaries. However, it contains an `orient` parameter which can be very useful for exporting your data, and also for looping through your data. \n",
    "\n",
    "Let's again use our `patients` dataset, convert it to a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6cb9d-3ade-49fa-8858-15ac5c9c341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d02b2f-0fa8-43eb-99d6-7eabeb9e6a12",
   "metadata": {},
   "source": [
    "You see that for each column, we have an entry, for exmaple the `age` has been exported with the `45`, `62`, `51`, etc, followed by `sex` contains `F`, `M`, `F`, and so on.\n",
    "\n",
    "By default, `to_dict()` defaults to using `orient=\"dict\"`, meaning each column's values has been exported as a dictionary. \n",
    "\n",
    "\n",
    "Let's change this to `list` and observe what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9201c18-4a14-478a-83af-ae5eef4e6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5e4df-ae16-4025-b105-a5cf99bd43f8",
   "metadata": {},
   "source": [
    "What can be seen is that each column in `patients` has now been exported as a list.\n",
    "\n",
    "Both `list` and `dict` return column oriented data.\n",
    "\n",
    "However, if you wanted to return row-based data, you can use `record`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d57ca3-7d47-4029-a31a-67caadd0072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7496f14-25b3-478e-9c7f-9c4bbf372bf6",
   "metadata": {},
   "source": [
    "Now, each row is returned as a dictionary. \n",
    "\n",
    "This makes it ideal for iterating over your patients. \n",
    "\n",
    "For example, we can using `for` to go over each `patient` in `patients`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72acd24-11e6-4eeb-86ff-919701bf4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in patients.to_dict(orient='records'):\n",
    "    print(f'Age: {patient[\"age\"]} BMI: {patient[\"bmi\"]} Diabetes: {patient[\"diabetes\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295026a-9879-4437-a2ec-0174020df3fd",
   "metadata": {},
   "source": [
    "Using `to_dict()` in combination with `orient=\"records\"` and a `for` loop can be a very convenient way to go over your entire dataset row by row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c0420-5d63-4383-8739-5e5aa872152e",
   "metadata": {},
   "source": [
    "## Built-in Plotting\n",
    "\n",
    "Pandas has some built-in plotting functionality, which can be convenient for exploring data quickly. \n",
    "\n",
    "The built-in functionality is not particularly powerful, but it can quickly output distributions and so on. The plots would not be considered publication level. For this we will cover dedicated plotting libraries later. \n",
    "\n",
    "For now, let's just plot the Data Frame as is, and see what we get out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae06e06-0fea-47f0-a432-38e23bc9a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.hba1c.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfec459-9342-4a8b-8d03-f139aa774d16",
   "metadata": {},
   "source": [
    "It takes some parameters, such as the type of plot, and the $y$-axis label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740c598-8027-4ae6-8ace-4ec5045922b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.hba1c.plot(kind='bar', ylabel='HbA1c (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a86484-1691-4c4c-94d8-a6e1e0d30eb7",
   "metadata": {},
   "source": [
    "Two columns can be plotted against each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3914e-218d-4bb0-b994-0447321245a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.plot(kind='scatter', x='age', y='hba1c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1bfe7b-df41-4b19-bd8d-123efbd5f543",
   "metadata": {},
   "source": [
    "Or a histogram which are binned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da549a-323f-4e47-a517-359d5def256a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4741ae2-295e-4514-877c-fcaf9f0d74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[\"hba1c\"].plot(kind=\"hist\", bins=8, xlabel='HbA1c (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec6fd4-2ea3-421e-8474-75282964ce8b",
   "metadata": {},
   "source": [
    "Generally speaking, you will use a dedicated plotting library to make plots, but it can be very useful to plot something quickly using Panda's built in plotting functionality. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ac578-668f-46f1-a9f5-5a0c1c7b44a5",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Your task is to analyse a tips dataset. \n",
    "\n",
    "> The \"tips\" dataset is a popular dataset often used for demonstration and practice in data analysis and visualisation. It contains information about various attributes of customers in a restaurant, including the total bill amount, tip amount, gender, whether the customer smokes or not, the day of the week, time of day, and the size of the party.\n",
    "> \n",
    "> From: <https://www.kaggle.com/datasets/sakshisatre/tips-dataset>\n",
    "\n",
    "\n",
    "Below we load the data as a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19495b80-d746-4abe-90a1-abd9cb26822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3d078-9599-4de8-be2b-67eea600eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e70c9-7348-48c8-a6d0-9e1ceab3a735",
   "metadata": {},
   "source": [
    "Use Pandas to:\n",
    "\n",
    "- Show the first 5 rows\n",
    "- Show the last 5 rows\n",
    "- Display how many rows and columns the Data Frame has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7eb823-173d-44d2-9378-d16196e2ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "tips.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafafd8-0dbe-4c80-a979-1842c158acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4d82f-f563-4248-8340-5234acf2e26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b6b7a-df58-4ba2-9b22-cae027a44bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476d2b4-d83e-4f2b-8b6b-33585ff6ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5ae70-2e2c-4f69-a174-c23d351ec997",
   "metadata": {},
   "source": [
    "Next:\n",
    "\n",
    "- Extract the `total_bill` column and save it to a variable `total_bill_col`\n",
    "- Select `total_bill` and `tip` together as a DataFrame called `total_bill_and_tip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e03d1b-ded2-41b3-93e8-180272616a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "total_bill_col = tips['total_bill']\n",
    "\n",
    "total_bill_and_tip = tips[['total_bill', 'tip']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65473e87-b3e0-43f2-afd4-129cc807adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bill_and_tip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091263c1-1ec2-4556-91b0-7464b83c10f2",
   "metadata": {},
   "source": [
    "Now:\n",
    "\n",
    "- Select all rows where `total_bill` is greater than 20.\n",
    "- Select all rows where `day` is \"Sun\".\n",
    "- Select all rows where `time` is \"Dinner\" **and** `total_bill` > 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa9b5d-18e5-46e1-99cc-5eeba8e3e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "# Tips greater than 20\n",
    "tips[tips['total_bill'] > 20]\n",
    "\n",
    "# Tips on Sunday\n",
    "tips[tips['day'] == 'Sun']\n",
    "\n",
    "tips[(tips['time'] == 'Dinner') & (tips['total_bill'] > 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e15690-59b6-48e0-abb5-c2461be4eff1",
   "metadata": {},
   "source": [
    "Finally:\n",
    "\n",
    "- Create a column `tip_ratio` defined as `tip` / `total_bill`\n",
    "- Display the first 5 rows of the updated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1558a-8480-48eb-93d5-0403391123bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "tips['tips_ratio'] = tips['tip'] / tips['total_bill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d35b4a-0710-401d-bec5-08ab87f7294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd1f6d-9ce8-400b-b931-3d31e9bb0401",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# NumPy\n",
    "\n",
    "If you are doing any kind of data science, you will eventually come across the NumPy library. \n",
    "\n",
    "NumPy is a library for manipulating arrays, which are like Python lists but far more advanced. NumPy is often used when working with large numeric datasets also because of its speed as it is optimised to perform operations very fast across your data.  \n",
    "\n",
    "It differs from Pandas in some fundamental ways. In many ways it is lower level than Pandas. It does not allow for custom indexes, or headers, and NumPy arrays cannot contain anything except numeric data. \n",
    "\n",
    "However, Pandas and NumPy compliment eachother, and you will often find that you will use a combination of both Pandas and Numpy: for example, you may perform some exploratory work using Pandas and then use NumPy to perform more compute intensive operations on your data.\n",
    "\n",
    "Because NumPy is quite low level, we will not spend as much time on it as Pandas, the advanced course goes in to much more detail regarding NumPy if you want to go in to more depth.\n",
    "\n",
    "## Basics of NumPy\n",
    "\n",
    "### Creating Arrays\n",
    "\n",
    "Fundamental to NumPy is the array data structure. 1-dimensional arrays are basically the equivalent of Python lists. 2-dimensional arrays can be considered like tables. 3D arrays are generally used to store images --- images often have several colour channels where each colour channel is one 2D array: so in in other words a 2D array for red, a 2D array for blue, and a 2D array for green, stored as one 3D array.\n",
    "\n",
    "![NumPy-Martrics](Images/numpy-matrices.png)\n",
    "\n",
    "However, in this course we will only look at 1D and 2D arrays. In the advanced course we cover 3D arrays, and even 4D arrays for example.\n",
    "\n",
    "There are various ways in which you can create arrays using NumPy. They can be created from standard Python lists, imported from CSV files, created from Pandas Data Frames, or generated with random numbers. \n",
    "\n",
    "Let us first create a 1D array from a standard Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172463a-3b84-40a6-9a46-d215a08d5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Convention is to import as np\n",
    "\n",
    "# Standard Python list\n",
    "l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Use array() function to create arrays\n",
    "l_np = np.array(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c569fa-d577-4c04-94d9-439f17de602d",
   "metadata": {},
   "source": [
    "This creates an NumPy array, `l_np`, from the list `l`.\n",
    "\n",
    "Use `type()` to show this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50461f81-93f4-4051-bbed-3b0becc34d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0775b94-48b9-478c-9e88-30c98e05282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(l_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc474d-b3bb-44f7-92fc-84c4d0eee5ac",
   "metadata": {},
   "source": [
    "Printing a NumPy array also looks slightly different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2c7df-11fd-470e-a223-c11ee39482d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eff21a-aabb-4dbd-ba74-8289355ffe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ceef48-b23a-4d62-ba89-2d7de82520f2",
   "metadata": {},
   "source": [
    "### The `arange()` Function\n",
    "\n",
    "As well as converting from lists, there are a few utility functions for creating arrays, for example `arange` that will create a range of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17f04f-3b2b-45b2-b698-2bfa2ffc81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a155d-886a-4fd1-bfd2-077938080c41",
   "metadata": {},
   "source": [
    "Again, it is the start index **inclusive** and the stop index **exclusive**!\n",
    "\n",
    "We can actually omit the start index and just provide a single number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc02bd-e5ab-4efc-bf99-6e31e5a80bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34f55e-6473-4648-bad4-e59283c3d0ef",
   "metadata": {},
   "source": [
    "We can specify also specify a step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22244a69-d6fb-4faf-a2c4-ce3a904a543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0606fe1-5f6e-4081-a7f0-3fa612fb3212",
   "metadata": {},
   "source": [
    "To specify a step, you need to provide a start index and stop index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5ba4f-8682-45be-b161-4fee79c18540",
   "metadata": {},
   "source": [
    "### The `linspace()` Function\n",
    "\n",
    "The `linspace()` function is used to create a linearly spaced array, where you specify a start value, a stop value, and the number of items you would like in between. \n",
    "\n",
    "Let's demonstrate it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b721269-f1c4-4801-b530-4476429e2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cc570-80b6-48ac-a644-0f8886142450",
   "metadata": {},
   "source": [
    "This creates 5 values spaced linearly between 0 and 1.\n",
    "\n",
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb498a35-d5cf-46ed-bee9-5bad709832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 100, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04824b7-7981-4118-9cef-6c13087cef69",
   "metadata": {},
   "source": [
    "### Creating 2D Arrays\n",
    "\n",
    "As we mentioned previously, NumPy can handle 2D, 3D and actually $n$-dimensional arrays. Here we will learn how to create and manipulate 2D arrays. In fact in this course we will not look at arrays beyond 2D, but the advanced course does cover this.  In machine learning, 3D arrays are generally used to store image data for use in deep neural networks, for example. As we do not focus on imaging in this course, we will not cover 3D arrays.\n",
    "\n",
    "Just as in creating a 1D array, we can create a 2D array with standard Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d427f-b353-43c6-8162-7e62e196e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 7, 9]]\n",
    ")\n",
    "\n",
    "l_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d67a71-8fe7-4887-b1e1-2a2559fb4ee2",
   "metadata": {},
   "source": [
    "Here we have provided NumPy with a list of lists. Each individual list corresponds to a row in our 2D tabular array.\n",
    "\n",
    "### The `zeros()` Function\n",
    "\n",
    "If you need to create an empty array with 3 rows and 4 columns, you can use the `zeros()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30262ce7-f805-446c-a9b4-08cb1921473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d = np.zeros((3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3a338-c348-418e-906d-9c232c22ba48",
   "metadata": {},
   "source": [
    "Which creates a $3 \\times 4$ array: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8c871-dd61-497a-9c7c-6a4f2365d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365b20f-0132-4f14-8429-8be19d158fd1",
   "metadata": {},
   "source": [
    "Which you can check using the `shape` property as we used with the 1D array above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4921f9-9527-45ae-83a4-fa6e895cf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26275742-dd6f-4727-89e8-9f5b833b3b13",
   "metadata": {},
   "source": [
    "### 2D Arrays with `arange()`\n",
    "\n",
    "Or if you want a table with a particular range of values, we can use the `arange()` in combination with `reshape()`.\n",
    "\n",
    "We saw above that the `arange()` funcion returns a 1D list corresponding to a range of values that you provide, in the form of a 1-dimensional list. Using the `reshape()` function, we can convert this into a tabular 2D array however. \n",
    "\n",
    "We do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14e79b-9071-41f4-b2b7-fe0c50eaaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(49)\n",
    "a = a.reshape((7, 7))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82992058-1ee5-4d85-89fd-aa7960f4e2d2",
   "metadata": {},
   "source": [
    "Using function chaining (which we mentioned briefly yesterday), we can also just say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98342383-69b1-4219-bcdd-efed565d347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(49).reshape((7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019cb577-224f-48a1-8859-e53d85d9e608",
   "metadata": {},
   "source": [
    "Of course, to make a table, the shape of the table you want to create must be valid. \n",
    "\n",
    "For example, this will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce299e44-d01d-4581-937e-d6fa73690c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(50).reshape((7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1214b-6599-473d-8814-e2c50e3219f6",
   "metadata": {},
   "source": [
    "You cannot create a 7x7 table with 50 elements.\n",
    "\n",
    "However, this would work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c51c0-9f6e-4c85-b86e-c8aa85e4ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(50).reshape((5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d892a7-e614-4584-a2c4-3d53a4c0e2f4",
   "metadata": {},
   "source": [
    "Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81f5d9-de15-4e38-a4a9-613ce129bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(50).reshape((10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609cd06-1f77-4d07-a661-09d04db793da",
   "metadata": {},
   "source": [
    "Sometimes it is easier to work backwards: think of a table shape that you want, e.g. 9x9, and then using `arange()` on 81 elements.\n",
    "\n",
    "### Creating 2D Arrays Using `linspace()` \n",
    "\n",
    "Just as with 1D arrays, we can use `linspace()`, but it must also be used in combination with `reshape()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263df09a-c5db-4187-b467-02448680d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1000, 16).reshape((4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2fdb7-d41c-4bee-a378-b52139f9a5b3",
   "metadata": {},
   "source": [
    "Now, the number of linearly spaced items, in this case 16, must be compatible with the shape of the 2D array you want to create ($4 \\times 4$).\n",
    "\n",
    "If we wanted integer values, we could add another method to the end of our chain, namely `astype()`, which allows you to change the type of the values within your array.\n",
    "\n",
    "We do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e286f12-f843-492c-ae8b-72f7310f5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1000, 16).reshape((4,4)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4980ab-5e46-4e2f-a466-caefd19d5041",
   "metadata": {},
   "source": [
    "Here we have passed `int` to the `astype()` function so that we convert our values in the array to whole numbers.\n",
    "\n",
    "### Creating a 2D Array with Random Values\n",
    "\n",
    "NumPy has its own set of random number generator functions. \n",
    "\n",
    "To create a random number you merely provide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c974d-cfdf-48a9-942d-4c19af74cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202c7ec-8b37-4994-aa2a-06e89de53df7",
   "metadata": {},
   "source": [
    "This creates a single random integer between 0 and 9. To create a 2D array of random numbers, we provide the `randint()` function with a `size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34328200-b4ac-4aed-aa4b-e6fb6c33ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(2, size=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10550e-6f44-4fec-af3b-224d33ae2d21",
   "metadata": {},
   "source": [
    "### Pandas and NumPy\n",
    "\n",
    "Pandas and NumPy work interopably when feasible. \n",
    "\n",
    "For example, we can create a Pandas Data Frame using a NumPy 2D array as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89c1e6-1334-442d-b1aa-3ff0a3e50f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = np.random.randint(9, size=(3,3))\n",
    "a_pd = pd.DataFrame(a)\n",
    "a_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d0f60-8695-44e9-a575-e63286b161dc",
   "metadata": {},
   "source": [
    "You can of course create a header and index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9dd154-84b8-45ac-8e8c-50032ca25bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(a, columns=['Patient 1', 'Patient 2', 'Patient 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82eb9ef-5441-46cf-ae1e-e8753078b12f",
   "metadata": {},
   "source": [
    "And provide an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88ca1f-b524-4240-8909-392497c3dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pd.DataFrame(a, columns=['Patient 1', 'Patient 2', 'Patient 3'], index=['Value 1', 'Value 2', 'Value 3'])\n",
    "pat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adac8bd-1321-4c78-b374-f0accc6cb643",
   "metadata": {},
   "source": [
    "So, here we use NumPy and Pandas together:\n",
    "\n",
    "- NumPy provides the raw numerical data\n",
    "- Pandas adds labels and tabular structure\n",
    "\n",
    "Likewise, we can export Pandas Data Frames as NumPy arrays. \n",
    "\n",
    "While this is possible using `np.array()`, such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e0312-4831-477b-950f-d8260eb931ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_np = np.array(pat)\n",
    "pat_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4904378-4e89-41d2-b337-34b79fd0b669",
   "metadata": {},
   "source": [
    "However, it is generally encouraged to use Pandas' built-in `to_numpy()` function to do this, as it is will likely do a better job in exporting the data to NumPy format, especially if you have a complicated dataset. \n",
    "\n",
    "This is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5ac95-2b68-4ff1-9d67-21c50f09ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_np = pat.to_numpy()\n",
    "pat_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4627b-1073-4fbe-81d1-f112653bf7e5",
   "metadata": {},
   "source": [
    "Here we are using the `to_numpy()` function of the Pandas Data Frame, rather than NumPy's `array()` function.\n",
    "\n",
    "Note again, NumPy is for numerical computation. If your Pandas Data Frame has non-nmerical types, it may not be possible to convert to NumPy, and even if it did, many of the functions in NumPy expect purely numerical datasets and will not work otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d0455-80ee-412c-883d-9f7c16e98e12",
   "metadata": {},
   "source": [
    "## Array Properties\n",
    "\n",
    "There are a few utility functions to get information about your arrays that are convenient.\n",
    "\n",
    "The shape property will tell you the number of rows and columns of your array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b00a446-f15a-479b-8e35-4dcbc66fffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6d08d-45c3-4785-ba78-a5c484d3e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84de2a-27cb-48d4-a592-eeacb0a6139f",
   "metadata": {},
   "source": [
    "The `ndim` property will tell you the number of dimensions of your array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1fc09d-d35b-4787-b30e-939dbd7c85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a37ae4-be4e-439a-bc11-abb781a0f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_np.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f018e3e-fce7-4bc4-b2c3-93fdfbe03288",
   "metadata": {},
   "source": [
    "2D means it is tabular data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af8092-9f4f-46a0-a825-206034e939cd",
   "metadata": {},
   "source": [
    "The size property tells you the total number of elements in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde16118-2944-4460-bda3-cc2845d14506",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_np.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edd2e4-c983-4bca-8f02-e4f35b496610",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b70d8-6f60-41a1-b265-1596d349b34c",
   "metadata": {},
   "source": [
    "The `dtype` property will tell you the type of the data contained in your array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0168628-9efc-4440-94af-5f7540a2548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d40a9-7e14-481e-a40f-1a7428db7612",
   "metadata": {},
   "source": [
    "## Array Functions\n",
    "\n",
    "NumPy arrays have a number of built in functions which can be very useful. \n",
    "\n",
    "These inlcude:\n",
    "\n",
    "- `a.sum()`\n",
    "- `a.mean()`\n",
    "- `a.min()`\n",
    "- `a.max()`\n",
    "- `a.std()`\n",
    "- `a.var()`\n",
    "\n",
    "We will demonstate some of these now. \n",
    "\n",
    "So, if you need to sum every element in in your array, you can use `sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9271bd-c7ab-465c-9ae4-97931e06618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first create an 2D array\n",
    "a = np.arange(32).reshape((8,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b089a8-0ea6-4ef8-b45a-12a10205382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8c17c-df9e-4a58-a855-8c3a10fdee4d",
   "metadata": {},
   "source": [
    "The largest value in your array can be found using `max()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de3574-9a73-4e4b-b905-de9d3f21bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05c865-710a-4d7c-9005-c2853d48c966",
   "metadata": {},
   "source": [
    "Likewise the minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d8fad-6b5a-4f9e-a113-ce7f51926d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f396183-9430-45c5-80d2-e1eda566463a",
   "metadata": {},
   "source": [
    "The average value can be found using `mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aea333-7e82-4586-beb3-6b9cb08af84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60013f-2e57-4c5e-844e-15ba27f56243",
   "metadata": {},
   "source": [
    "### Row and Column Operations\n",
    "\n",
    "Many of these functions can be applied column-wise or row-wise using the `axis` parameter.\n",
    "\n",
    "For example, `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279a04b-aa4e-4d17-9be4-193f1213440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=0)   # column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1304a8-f2b9-45bd-a79f-c68b7372cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=1)   # row-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17321552-7e24-4f7c-88e4-51cf611247d1",
   "metadata": {},
   "source": [
    "Notice that `sum()` now returns multiple elements. When `axis` is set to `0`, the `sum()` function is applied column-wise, and therefore 4 values are returned as our 2D array is a $8 \\times 4$ array, and we get one summation for each column of the array.\n",
    "\n",
    "Likewise, when setting `axis` to `1`, we are saying that we wish to apply the function row-wise, and hence 8 values are returned, one summation for each row.\n",
    "\n",
    "The same can be done for `mean()`, `min()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c0ef0-6bef-4b3b-ae67-26b1094df81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean(axis=1)  # row wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1f733-87e1-440f-9093-286a0c5be012",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.min(axis=0)  # column wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c7071-f599-48b9-a297-63c6572139f5",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "You can use the `sort()` to sort either each row, or each column.\n",
    "\n",
    "Let's make a unsorted array to demonstate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69695638-6cc8-4315-b63f-e92eb55ec71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randint(100, size=(6,6))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649fe73-d222-40bc-89bb-24a3d3bcecf5",
   "metadata": {},
   "source": [
    "Now sort the columns in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a919d75-9cc5-489f-80a8-3fc0f27d53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.sort(axis=0)  # Column-wise\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f321e-5eaa-4f3c-896f-88e74fc20576",
   "metadata": {},
   "source": [
    "And conversely, we can sort the rows in the ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed32f7-ebac-4bb7-bca3-a5a1a6158e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.sort(axis=1)  # Row-wise\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74deae03-2b1f-433e-822c-0ceb583281eb",
   "metadata": {},
   "source": [
    "Again, we specify whether we want columns or rows with the `axis` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bd195-2a1c-4c3a-bc41-4e40bb5a86db",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "Where NumPy can be very useful is the indexing and slicing of your data. \n",
    "\n",
    "As with Python lists you can select a subet of a 1D array quite easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fee7c-a70f-405c-b539-a10410465a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af0937-131e-486e-85d1-5bd09bfc5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89a56d-9511-4ff3-a38f-37d87b07a916",
   "metadata": {},
   "source": [
    "Or a range can be selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1a28e-649b-463d-ad28-b9a59846e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4b2a1-104e-4cda-86f7-09e1f69d2b14",
   "metadata": {},
   "source": [
    "Again the start index is included, while the stop index is not.\n",
    "\n",
    "If you omit one of the values around the colon `:` it means, \"from the begining\" or \"to the end\".\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6dba6-9ea4-40b8-b3e0-11dc5492a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634db01-5284-41e1-a2e9-d56712b563c2",
   "metadata": {},
   "source": [
    "is the same as saying `l[0:5]`.\n",
    "\n",
    "Likewise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fb872-b4c0-40a3-b650-a7e0f48e1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56f721-8ef9-4ad2-b869-b1419881a297",
   "metadata": {},
   "source": [
    "We can also specify a step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ac144-452e-46c9-853c-7c6b82b3615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0:8:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca2b8cf-8ab8-47ff-a660-3cc3382c1666",
   "metadata": {},
   "source": [
    "Therefore, the indices take the form `start:stop:step`, where `step` is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11283033-f332-450d-bacb-86f6d97a693f",
   "metadata": {},
   "source": [
    "If tou only inlcude a step, you will get every step's element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164106d5-00fb-4353-98ee-dfaa16d888ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391a170-2af7-43c7-bb26-bd074ead364d",
   "metadata": {},
   "source": [
    "Negative indices from the end of the array to the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12428c7e-b983-4a7f-b27f-1d1169eba4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f0258-b01e-460e-a2db-dc0d2c7d67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[-5:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079e23f-a3aa-4dc7-8c88-cd337dfa2998",
   "metadata": {},
   "source": [
    "This can be slightly confusing, however often you will see this used to get the last $n$ items from a list, e.g. to get the last 3 elements of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9adca-7cbe-4767-a977-421dfd8e8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b5025-2e68-4d37-884c-0632f1cb8439",
   "metadata": {},
   "source": [
    "### 2D Array Slicing\n",
    "\n",
    "2D array slicing is a particular strength of the NumPy library.\n",
    "\n",
    "Let's first create a 2D array to demonstate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1350489-7de6-4d39-845a-2624d42a6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(36).reshape((6,6))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd695ed-f64d-4b4e-b4a4-6b41c2f028f1",
   "metadata": {},
   "source": [
    "We can select individual elements using two indices, one index for the row and one index for the column. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09debc95-210b-48d0-bb6b-ed13b832b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbe0bb-486f-4a33-87ea-1f635c07ea1e",
   "metadata": {},
   "source": [
    "If we wanted the 3rd element in the 3rd row (this is the value `14` in the array above), we'd say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321e784-f9a6-4258-bb21-f4aed946e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4c43f-a094-4cb6-b37d-4e75b4a140c6",
   "metadata": {},
   "source": [
    "As you can see, to slice 2D arrays, we seperate the indices for the rows and the columns with a `,`.\n",
    "\n",
    "We first specify the rows, and then the columns, so it takes the form:\n",
    "\n",
    "```python\n",
    "array[row_indices, column_indices]\n",
    "```\n",
    "\n",
    "### Slicing With Ranges\n",
    "\n",
    "We can use the colon `:` character to use index ranges, as we saw above.\n",
    "\n",
    "So, if we want to select only the first row, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce082407-3ebc-47ac-aee3-4b1b39f0a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1e253-933c-40e5-bbf4-35a105ff847f",
   "metadata": {},
   "source": [
    "What we have done above is to say we want the first row, row 0, and all columns, which can be represented with the colon `:` character.\n",
    "\n",
    "Let's select only the first column in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ca7cc-e18e-4de4-a37d-8ceaeb65992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d533e2-54ea-426e-9bc1-584a12756118",
   "metadata": {},
   "source": [
    "Here we use `:` to say we want all rows, followed by `,` and then we specify we want column `0`, the first column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff6344-0fbd-457a-b70c-d04dd18f7c98",
   "metadata": {},
   "source": [
    "We can also use negative indexing, so we might say we want the last two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74718d-df8a-4b50-87d7-352eed014ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, -2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358de90-d0bc-419f-9877-35e0b3bd481a",
   "metadata": {},
   "source": [
    "Or the last row, all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ab54a-d611-4c9d-b1f4-918bde0404c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc88e2-173c-47e5-90ff-c2a71a3c87cf",
   "metadata": {},
   "source": [
    "Last, we can also specify a step, as with the 1D arrays above.\n",
    "\n",
    "So we might say we want every second column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50965ef1-ece0-4a79-8a8d-73d09faaf5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875abe2-e2da-4a82-98c1-b0d51c082d5b",
   "metadata": {},
   "source": [
    "Or every second row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e6f31-69d3-4c41-bb88-fb1597b05cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[::2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fcc24e-c3de-48b2-9c61-553dbe54703c",
   "metadata": {},
   "source": [
    "And combine these techniques to some clever indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92052296-0b8a-48fa-870f-48549d8a9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[::2, :-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11239389-2584-4939-a42c-e0d8251bb171",
   "metadata": {},
   "source": [
    "Here we have said we want every second row, for all columns except for the last 2.\n",
    "\n",
    "Slicing can also be performed on 3D arrays and beyond, however we will not cover this during this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1bb881-b056-4566-8cb6-679ca2f531a0",
   "metadata": {},
   "source": [
    "## Array Broadcasting\n",
    "\n",
    "One particular feature of NumPy that makes it useful for scientific computing is array boradcasting. \n",
    "\n",
    "These are one line expressions where you can do element-wise operations on arrays, without needing to write loops.\n",
    "\n",
    "Let's demonstrate this with some code. \n",
    "\n",
    "Imagine you had two standard Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87bf5e-ebfd-47b8-b721-da110f16d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [10, 20, 30]\n",
    "weights = [1.1, 2.2, 3.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d54f76-b833-4f19-9a23-7584a2f5b9d2",
   "metadata": {},
   "source": [
    "And you wish to multiply the values in `a` with their corresponding values in `weights`.\n",
    "\n",
    "If we try this with standard Python lists, we will get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce808c-d4bd-4810-b18b-f2ee6d648c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a * weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c44b82-446b-4710-b1b3-d3fe8e92734b",
   "metadata": {},
   "source": [
    "As we cannot multiply two lists together, we will have to loop over the lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b2d5c-1427-4691-acc7-8678736e192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sums = []\n",
    "\n",
    "for i in range(3):\n",
    "    t = a[i] * weights[i]\n",
    "    weight_sums.append(t)\n",
    "\n",
    "weight_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95456de2-d783-4710-8dde-e6714c83fb2d",
   "metadata": {},
   "source": [
    "However, if we convert those lists to NumPy arrays, we can do this in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78aec13-9750-4129-8c0c-a2bdd281d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "weights = np.array(weights)\n",
    "\n",
    "a * weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a06d7e-3cda-4b0a-b4f3-0d6681e24cb4",
   "metadata": {},
   "source": [
    "No loops required, NumPy has multiplied, element wise each element of `a` with its corresponding element in `weights`.\n",
    "\n",
    "The same goes for addition. \n",
    "\n",
    "Let's take these standard Python data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bff67-353c-4be4-b159-3601ef6c0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]\n",
    "\n",
    "b = [10, 20, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d69927-dff2-4f2f-aa58-415787c7f9b1",
   "metadata": {},
   "source": [
    "If I wanted to add each row of `a` with `b` I could try using addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930d10a-0e3a-44d4-bffa-102c53daceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac242f-a128-4f4a-b2bf-f0f5fdf9ec44",
   "metadata": {},
   "source": [
    "While it doesn't fail, it has not done what we wanted.\n",
    "\n",
    "If we do this with NumPy arrays however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db982a7-9fbf-402d-832a-b86ad681739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019c906-6c38-4948-9306-f2ed0c791b58",
   "metadata": {},
   "source": [
    "Again compare this to having to write a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf2be0-31fc-4ec0-a8b1-f611319f1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]\n",
    "\n",
    "b = [10, 20, 30]\n",
    "\n",
    "new_matrix = []\n",
    "\n",
    "for row in a:\n",
    "    new_row = []\n",
    "    for element, addition in zip(row, b):\n",
    "        new_row.append(element + addition)\n",
    "    new_matrix.append(new_row)\n",
    "\n",
    "new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ab858-e914-4c30-a271-890dad59c812",
   "metadata": {},
   "source": [
    "Even something as simple as adding a number to every element in a Python list results in an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cbaa7-f3d2-46dc-8f33-198b172b9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "l + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6fb92-706d-4c31-8a93-04aeec4d4afd",
   "metadata": {},
   "source": [
    "However, as you might have guessed, using NumPy this can indeed be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faad9f1-5864-488f-81d1-27604e9cb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "l + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27705da4-e218-4a1b-92b9-b9643415ee8d",
   "metadata": {},
   "source": [
    "The same goes for `*` and `/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc99372-877b-4ac6-ac9c-235158f366aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "l * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46980c1a-b8da-4f01-b885-a4df6e0393f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77602a-f7d7-4032-ba48-b07afc663d3f",
   "metadata": {},
   "source": [
    "These operations also apply to 2D arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dba698-c61c-42a2-a08c-97808f3cce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(9).reshape((3,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b9f51-a912-4f4c-93f2-a80420ed3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0139c7-6929-4900-b81a-fed8bfd8d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "a * 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d584877-059f-4ff5-8955-6b25f84e7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1a33a-232b-440a-b1b5-80946a0ff969",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0ffc1-93cc-4834-af21-97dc6dd36045",
   "metadata": {},
   "outputs": [],
   "source": [
    "a ** a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f6723-0687-40bf-b761-fc90073bd1e7",
   "metadata": {},
   "source": [
    "Therefore, with array broadcasting, you can perform element wise operations on your arrays without the need for writing loops over your data. \n",
    "\n",
    "Not only this, but array broadcasting can be up to 100 times faster than looping over each element in a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59f700-fecc-423b-8993-02882a98d363",
   "metadata": {},
   "source": [
    "### Searching Arrays\n",
    "\n",
    "We will finally briefly cover searching of arrays. \n",
    "\n",
    "You can specify conditions in order to search arrays for particular values that meet these conditions. \n",
    "\n",
    "Let's create an array and look at a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9aa99-1ac5-44c8-8e30-94552472caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5246134-275c-4da5-9d44-393b5712434b",
   "metadata": {},
   "source": [
    "We can specify our conditions just how we specify indices. If we wanted to find all values greater than 5, we can do so as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee9f94-2e1d-4bb5-9987-da698109452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d451eaf-5e2d-4031-be3d-b532f2ae5738",
   "metadata": {},
   "source": [
    "Note that it returns an array of values, and loses its shape. The array a was a 2D array, and we got back a 1D array of values. This is often what you want, but not always, so be aware of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcd1c2-b871-4df5-935c-414680bee14e",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "\n",
    "Create slices for each of the colours represented here:\n",
    "\n",
    "<img src=\"Images/slicing-task.png\" width=\"300px\" />\n",
    "\n",
    "To be clear:\n",
    "\n",
    "- the orange coloured slice includes numbers 3 and 4.\n",
    "- The red slice is the entire column, 2, 8, 14, 20, 26, and 32\n",
    "- The blue slice is square shaped, and includes 28, 29, 34, and 35\n",
    "\n",
    "Step 1:\n",
    "\n",
    "Recreate the array above. It has 36 elements, numbers 0-35, in the form of a $6 \\times 6$ 2d array. You can do this using `arange()` and `reshape()`.\n",
    "\n",
    "Store this in a variable called `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1d348-96c2-465e-81e2-9a4d4f6909f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(36).reshape((6,6))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24579c-3db3-48df-98fc-9e5c082ed93d",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "\n",
    "Now perform the slices for each of the coloured elements above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d213bfa-f9f8-4a36-bb12-a413c0a253be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39080a1a-f8b2-4794-a95d-8bd25ce544f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Plotting\n",
    "\n",
    "We will cover some basics of plotting in Python now. \n",
    "\n",
    "The most use library in Python for plotting is Matplotlib. Seaborn is another package that is popular. \n",
    "\n",
    "In this seminar we will use Matplotlib, but the concepts will apply also to Seaborn and other plotting libraries.\n",
    "\n",
    "First let's import. Convention is to import `matplotlib` as `plt`, so often you will see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24281ced-5150-4b9f-9a8a-7dc2c16f5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65eadbb-295c-4ea1-8b78-ba48269ea701",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]\n",
    "y = [3, 7, 9, 12]\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2b250-bf90-4929-aa30-ca4557c6dac4",
   "metadata": {},
   "source": [
    "A lot of adjustments can be made to the look of your plots. The basics are for example the line style or the marker style, as well as colour options.\n",
    "\n",
    "Here we adjust the colour to red, use round markers, and define the a dashed line style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b058a-f551-4f42-a768-5344a1e0b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, color='green', marker='^', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a21f0a-0432-456a-9418-0f66ee0b2371",
   "metadata": {},
   "source": [
    "You can also add a label to your plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0dc290-55f6-43fa-8ba2-7fcebd9c3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, label='Data 1', color='red', marker='o', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0e0c1-56d5-4f90-9550-ef77a5f97508",
   "metadata": {},
   "source": [
    "Be aware that you then need to call `plt.legend()` before calling `plt.show()`. \n",
    "\n",
    "This is because you label each line on your plot individually and then called `plt.legend()` to apply the labels to a legend.\n",
    "\n",
    "Speaking of multiple lines, we can just add them one by one before calling the final `plt.show()`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cad236-a371-4d03-baef-e0db53cf0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.plot(x, [x*x for x in x], label='y = x²')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348fcd1-bae9-44fc-8359-904294dbed0c",
   "metadata": {},
   "source": [
    "You can add a title to your plot using `plt.title()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c810e8c-f7d7-49a5-b9b8-aa340f07435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.plot(x, [x*x for x in x], label='y = x²')\n",
    "plt.legend()\n",
    "plt.title(\"Line Plot Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6b3eb-7016-4afc-ae86-9583a28ef6c5",
   "metadata": {},
   "source": [
    "You can change the look and feel of the plots quite easily using styles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48195b85-8ff5-43de-ba48-a6f83225f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646f7b7-f285-4ac6-ad49-498cfade7059",
   "metadata": {},
   "source": [
    "This is now set to mimic the style of ggplot, the most commonly use R plotting library which you will learn about in the next half of the course.\n",
    "\n",
    "If we now make another plot, we will see the new style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252655b-37d4-4389-b901-80cc0594c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.plot(x, [x*x for x in x], label='y = x²')\n",
    "plt.legend()\n",
    "plt.title(\"2 Line Plot Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaeba6d-b35d-4696-b6e5-fd59d64d6349",
   "metadata": {},
   "source": [
    "You can find all styles by using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97534124-f150-4707-bdc8-f07093e0c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da6415-92e6-46b5-bb6a-021be16948e1",
   "metadata": {},
   "source": [
    "Some are quite nice, such as `fivethirtyeight`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c812d-8a4d-4076-926d-efdd3c877718",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, [x*x for x in x], label='y = x²')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fb806-c4e4-44c8-aaac-6e1e82a0c293",
   "metadata": {},
   "source": [
    "The most common plots are supported:\n",
    "\n",
    "- Line plots\n",
    "- Scatter plots\n",
    "- Bar plots\n",
    "- Histogram plots\n",
    "- Box plots\n",
    "- Pie charts\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043400d-fd86-4791-9897-def0459bf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.random.randn(100), np.random.randn(100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d292d8-fd16-4b6d-a3b5-feff275a556a",
   "metadata": {},
   "source": [
    "Bar plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76190b-def0-46eb-85a9-d2a25f043f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psoriasis = ['Pustular', 'Erythrodermic', 'Guttate']\n",
    "counts = [10, 7, 5]\n",
    "\n",
    "plt.bar(psoriasis, counts)\n",
    "plt.title(\"Psoriasis Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e0520-2929-4aed-b00d-0552e7c2d910",
   "metadata": {},
   "source": [
    "Histogram plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b561bf1-4d4d-4e63-b983-4b7a706d22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(1000)\n",
    "plt.hist(data, bins=30)\n",
    "plt.title(\"Histogram Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b3b13-2806-44bf-a5cb-3f5b1ced597b",
   "metadata": {},
   "source": [
    "If you want to export a figure, this can be done using the `savefig()` function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863a11c-89af-4d09-9227-d054c8b0043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5806a74-f444-4344-8d9a-8530d3150ff3",
   "metadata": {},
   "source": [
    "Matplotlib will infer the file type from the extension. PDF is useful as they are saved as vector graphics and can be embedded into publications. PNG might be more useful for embeddeding in Word documents or sharing plots on the web.\n",
    "\n",
    "Other options that might be useful are the following:\n",
    "\n",
    "- `plt.grid(True)`\n",
    "- `plt.xlim(0, 5)`\n",
    "- `plt.ylim(0, 10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae2ae2-775b-413a-a16c-e95eb5f021c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe0140-99dd-4116-98aa-accf28f76185",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1, 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a87ec2-2311-403f-9590-da4e9240afae",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "### Histogram\n",
    "\n",
    "Create a histogram with 1,000 random numbers. \n",
    "\n",
    "To generate the 1000 random numbers you can copy and paste the snippet below:\n",
    "\n",
    "```python\n",
    "data = np.random.randn(1000)\n",
    "```\n",
    "\n",
    "- Create the histogram with 25 bins.\n",
    "- Add grid lines and a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23919fc5-f8dd-464c-923a-cd87e3f8d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c239b0-7022-4bea-81a6-5e04a565b2ae",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Create a plot with **three** lines. We have already defined `x` and `y` above, so we will first create another list called `z`. The `z` list needs to be the same length as `x` and `y`.\n",
    "\n",
    "Line 1 should be `x` vs. `y`, line 2 should be `x` vs. `z`, and line 3 should be `z` vs. `y`.\n",
    "\n",
    "Style each line differently. One with round markers, one with square markers, one with triangular markers.\n",
    "\n",
    "Give each line a width of 2.\n",
    "\n",
    "Give each line a label. \n",
    "\n",
    "Use the theme `bmh`.\n",
    "\n",
    "Plot it and save it as a PNG, with a DPI (dots per inch) of 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2b149-62ac-463f-8a8a-64e4f14c8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffca7f7-2ce4-4730-8cfe-9e1a7cba1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [1.5 ,4.5, 10.9, 15.5]\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "plt.plot(x, y, linewidth=2, marker='o', label='x vs. y')\n",
    "plt.plot(x, z, linewidth=2, marker='^', label='x vs. z')\n",
    "plt.plot(z, y, linewidth=2, marker='s', label='z vs. y')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('plot.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a6871-b2ac-4fcb-b2e5-6043d90c7e69",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4034d76-4ec4-481f-b75c-59c2701eb393",
   "metadata": {},
   "source": [
    "Databases do not work like regular files. You have to connect to them, and once a connection is established, you need to create a \"cursor\" which defines where in the database you currently are, like a pointer.\n",
    "\n",
    "We shall do this now to a sample database we have on our computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab4997-da5b-44e2-bc0d-2793f1568698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"sample_db.sqlite\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33315749-3369-43cc-8f2e-dd20369da940",
   "metadata": {},
   "source": [
    "To get data you need to run SQL commands. SQL commands are their very own type of language. \n",
    "\n",
    "A database typically consists of several tables. These tables are often joined via relationships. We will not go in to databases in much detail here. We can view the contents of the database under the following URL: <https://sqliteviewer.app/> (open the link and click \"**Load a sample**\"—this will open the same database we will open here in the notebook).\n",
    "\n",
    "To get data from the database, you use the `SELECT` command. Here we select everything (using `*`) in the `Invoice` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5892df9-750d-4c8f-9309-e9f71bd07d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM Invoice\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7f791-d6ea-452c-9d49-a28a9db28db4",
   "metadata": {},
   "source": [
    "We can now look to see how many rows were retrieved, and maybe have a look at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35bc2e-b7bb-4c72-89c3-27634b4df229",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02884f6c-3268-4ba5-9fc6-fbda3db9a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341cc1a-60eb-48d9-b65d-edd9340b02ee",
   "metadata": {},
   "source": [
    "We may want to know what these fields all are, and for this we can use the `PRAGMA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c972e89-1c2a-4fa5-b4a7-b2c8972461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"PRAGMA table_info(Invoice)\")\n",
    "columns = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13164591-807a-4293-8e0e-2ffd11b59fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787d581-3c79-4c52-8c1d-4029e4f7c6c6",
   "metadata": {},
   "source": [
    "We can do very advanced searches using SQL, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da2b50-e23b-4973-9652-8ea9795aaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT BillingCity, Total FROM Invoice WHERE BillingCountry = 'United Kingdom'\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6a394-ea31-455c-93b6-ea088af93d4a",
   "metadata": {},
   "source": [
    "Let's inpect the rows now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483db172-3cf5-45f0-b273-dda1f25e477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f9dee-8012-47ed-a0ef-36a08e4dc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86448577-0fb8-4c35-85c0-dac24740367c",
   "metadata": {},
   "source": [
    "What if I wanted to find the total sales?\n",
    "\n",
    "To do this, we can use the `SUM()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989eb70-c605-4122-9929-77985d8c6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT\n",
    "        SUM(Total) AS total_sales\n",
    "    FROM Invoice\n",
    "    WHERE BillingCountry = 'United Kingdom'\n",
    "\"\"\")\n",
    "\n",
    "total_sales = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd14faf-2a75-4578-909a-3ad0cfcc074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f5116-fa70-49e8-a05d-a3a49f531f76",
   "metadata": {},
   "source": [
    "Imagine you wanted to break the orders down per city? \n",
    "\n",
    "This time we will search for orders from the USA, and use `GROUP BY` along with the city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176cc36-84a1-4367-91fc-aba9380eebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT\n",
    "        BillingCity,\n",
    "        COUNT(*)   AS total_orders,\n",
    "        SUM(Total) AS total_sales\n",
    "    FROM Invoice\n",
    "    WHERE BillingCountry = 'USA'\n",
    "    GROUP BY BillingCity\n",
    "    ORDER BY total_sales DESC\n",
    "\"\"\")\n",
    "\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5a618-fac8-4e21-9daa-594789e70f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385dc245-633e-43e1-89a9-3274d2ecfaaa",
   "metadata": {},
   "source": [
    "What if we wanted the total sales, per month, per country?\n",
    "\n",
    "Well we can use the `GROUP BY` command twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819bf57-6593-4869-8a21-71956247e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \"\"\"\n",
    "SELECT\n",
    "    strftime('%m/%Y', InvoiceDate) AS year_month,\n",
    "    BillingCountry,\n",
    "    COUNT(*)        AS total_orders,\n",
    "    SUM(Total)      AS total_sales\n",
    "FROM Invoice\n",
    "GROUP BY year_month, BillingCountry\n",
    "ORDER BY year_month, total_sales DESC;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(stmt)\n",
    "\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b6a2e-e799-43d5-a8ee-6240afe20be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185cf19-b09e-480b-8c23-e75cb6bd9b71",
   "metadata": {},
   "source": [
    "## Interfacing with Pandas\n",
    "\n",
    "Pandas can run SQL statements on a database directly.\n",
    "\n",
    "Using our `conn` earlier, this is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5556e4-6fbb-4da7-b3de-508b748a339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\n",
    "    \"SELECT * FROM Invoice\",\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806a0d1-d799-44e2-97da-a8e201a37beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e759a-5ce5-424a-850c-c1a883db4324",
   "metadata": {},
   "source": [
    "Let's say I want the order per country and to plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f905e-9ee7-4f38-90de-ce21f8ac10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \"\"\"\n",
    "    SELECT\n",
    "        BillingCountry,\n",
    "        COUNT(*)   AS total_orders,\n",
    "        SUM(Total) AS total_sales\n",
    "    FROM Invoice\n",
    "    GROUP BY BillingCountry\n",
    "    ORDER BY total_sales DESC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(stmt, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4075727-b438-419e-8514-cb709a85fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a0aca-10fd-453b-be6b-5ef7a16b336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"BillingCountry\",\n",
    "    y=\"total_sales\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a4ecf-2c1b-45de-b897-a81723d61a83",
   "metadata": {},
   "source": [
    "### Write to SQL Database\n",
    "\n",
    "Of course, you can write to a database, and can be done directly from within Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b985e-90a0-4895-acab-ba57f1512157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\n",
    "    \"SELECT * FROM Invoice\",\n",
    "    conn\n",
    ")\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b77459-24f6-4039-b133-ac867b19c631",
   "metadata": {},
   "source": [
    "So if you remember your Pandas from above, we can use the `loc` indexer to change a value.\n",
    "\n",
    "Here we are changing the data in the **Data Frame** for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d87e68-0927-4f5c-b598-9b02d1602243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[411, \"Total\"] = 1000.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5e5df-8ef2-42b6-acb5-d06e834b8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04627f33-b481-4235-a8d7-d85e653e5e68",
   "metadata": {},
   "source": [
    "Now that we have changed the data in the Data Frame, `df`, we can write this back to the SQL database.\n",
    "\n",
    "This will override the data if we use the `if_exists=\"replace\"` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed080eb1-982b-44d1-a2a6-c220f3d2afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"Invoice\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a59e5-691f-45a6-811c-6d4424dc1476",
   "metadata": {},
   "source": [
    "Now that this has been writtten back to the database, we can re-read the data from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6114da-b3a4-4832-b636-9900d03efbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(stmt, conn)  # stmt is defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b68e6-58ed-45ed-ac9b-fd52bb663f00",
   "metadata": {},
   "source": [
    "And now plot again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c785329-824c-4139-90ac-2bbadf5e0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"BillingCountry\",\n",
    "    y=\"total_sales\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d855f96-4f0a-4e1d-a2ef-4989a3118713",
   "metadata": {},
   "source": [
    "It is good practice to close a connection once you are done with it, and we do so as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10bc04-7e30-40cb-b787-77177ad0aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061c6e3-00af-4208-b02c-fbcd061bde5c",
   "metadata": {},
   "source": [
    "You can see if we try to run a command on the database now, it will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1caad18-4fd7-4b5e-8b2a-7107d3e719c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM Invoice WHERE BillingCountry = 'Ireland'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe766b84-9077-44dd-a99f-cdfaabf44fab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e161607-1733-45e2-8ee5-a5178bb83258",
   "metadata": {},
   "source": [
    "# Machine Learning and SciKit Learn\n",
    "\n",
    "In this section we will cover the bascics of **Machine Learning**. \n",
    "\n",
    "We cover this last, as a prerequisite for any \n",
    "\n",
    "## What is Machine Learning\n",
    "\n",
    "What exactly is **machine learning**?\n",
    "\n",
    "To quote Arthur Samuel, a early AI pioneer, it is \"the field of study that gives computers the ability to learn without explicitly being programmed\". \n",
    "\n",
    "In other words, machine learning gives computers the ability to learn algorithms. These are the algorithms a computer programmer would normally have to design for himself or herself, but machine learning has the ability to learn algorithms merely by looking at data. \n",
    "\n",
    "So, unstead of writing instructions like \"if X then Y\", you provide the machine learning algorithm examples (data).\n",
    "\n",
    "The computer analyses these examples, identifies patterns, and builds a model that can be used to make predictions on new, unseen cases.\n",
    "\n",
    "### Simple Example\n",
    "\n",
    "Diagnosing disease from symptoms:\n",
    "\n",
    "- Input: Age, blood values, lab values.\n",
    "- Output: Diagnosis.\n",
    "- Process: Provide many past cases with known diagnoses. The algorithm learns which patterns in the inputs are associated with which diagnoses. This is also known as **training** the algorithm.\n",
    "- Result: For a new patient, the model predicts the most likely diagnosis.\n",
    "\n",
    "Important to note: no understanding, reasoning, or intent is involved. Only statistical pattern extraction.\n",
    "\n",
    "But why would you want to write an algorithm like this? Why not programme it explicitly? The main reason is that the rules are far too complex to write down and actually programme. Or, we do not even know the underlying patterns behind the data, and have yet to discover them. But, we may have lots of data, and wish to see if a pattern in this data does exist. \n",
    "\n",
    "### Recent Developments \n",
    "\n",
    "Machine learning is both an established field, and is also the technology behind many of the innovations we have seen recently, such as ChatGPT and Large Language Models in general, as well as image generation, image classification, voice and speech understanding and synthesis, and so on.\n",
    "\n",
    "In medicine, for example, machine learning is used extensively, with recent devlopments in image classification being perhaps the most prevalent. For example, in dermatology machine learning is used to classify skin lesions and moles, in pathology it is used to to analyse histological samples and classify disease, in radiology it is used to segment and isolate tumours 3D MR imaging, and so on.\n",
    "\n",
    "![Example Medical Images](./Images/example-med-images.png)\n",
    "\n",
    "> Woerner, S., Jaques, A. & Baumgartner, C.F. A comprehensive and easy-to-use multi-domain multi-task medical imaging meta-dataset. Nature Scientific Data 12, 666 (2025). https://doi.org/10.1038/s41597-025-04866-4\n",
    "\n",
    "ChatGPT, image classification, image generation, and so on have mostly been developed through the use of **Deep Learning** which are basically very large neural network algorithms. We will not cover deep learning in depth in this course, however if you are interested in this topic, the advanced course covers deep learning in some detail, especially the classification of medical images.\n",
    "\n",
    "In this course, we will study more 'classical' algorithms and apply them to tabular-based datasets. \n",
    "\n",
    "## Categories of Machine Learning\n",
    "\n",
    "There are two main types of machine learning approach, supervised methods and unsupervised methods. The vast majority of machine learning methods are supervised. We will cover both supervised and unsupervised algorithms here, but with more of a focus on supervised methods.\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "A supervised machine learning problem is defined as one where you train it with examples the include both the input data **and** the correct outcome. \n",
    "\n",
    "Therefore, each training sample/example/patient consists of:\n",
    "\n",
    "- Input ($X$): measurements, lab values, etc.\n",
    "- Label ($y$): the known correct diagnosis\n",
    "\n",
    "The machine learning algorithm learns a mapping from the inputs to the labels, so that you get end up with a function, that takes the data as its input and provides a prediction:\n",
    "\n",
    "$$\n",
    "f(X) \\approx y\n",
    "$$\n",
    "\n",
    "The procedure is more or less as follows:\n",
    "\n",
    "- Provide the machine learning algorithm many examples\n",
    "- The algorithm makes predictions\n",
    "- You calculate the error by comparing the prediction with the true value\n",
    "- The parameters of the model are adjusted to reduce the error\n",
    "- Once trained, you apply this trained function to new, unseen data\n",
    "\n",
    "Within supervised learning there are also two main subtypes **classification** and **regression**. \n",
    "\n",
    "- Classification: the output is a categroy, such as disease, benign vs. malignant, etc.\n",
    "- Regression: the output is a number, such as blood pressure, disease progression, tumour size, etc.\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, there is not target variable. In other words, we do not have any labels for our data. \n",
    "\n",
    "Unsupervised learning is generally used for exploratory analysis of data. One example is clustering, where data is group in to clusters based on the similarity of the data.\n",
    "\n",
    "In this seminar we will cover a clustering algorithm and see how we can apply it to some data.\n",
    "\n",
    "## Key Terminology\n",
    "\n",
    "Before we go any further, let's cover some basic terminology and we will also cover some conventions we will use for writing our code.\n",
    "\n",
    "Let us define the following terms:\n",
    "\n",
    "- **Features**: these are properties about the sample in question. In a house dataset, this would be square metres, does it have a pool, neighbourhood, etc.\n",
    "- **Labels** or **targets** or **classes**: this is what you are trying to predict. They are also what you need to supply an algorithm in a supervised setting, during training. In the house price dataset, this is the price of the house.\n",
    "- **Training data**: what we use to train our algorithm.\n",
    "- **Test data**: what we use to validate and test our algorithm. These are normally a subset of your total data.\n",
    "\n",
    "By convention your training data is stored in `X`, uppercase and your label data is stored in `y`, lowercase.\n",
    "\n",
    "Also, if you are splitting our data into training and test sets, you will see the following `X_train`, `X_test` will contain our training data, and `y_train`, and `y_test` will contain our corresponding labels.\n",
    "\n",
    "We will explain later exactly what the purpose of the training and test set data are.\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "This table summarises the various types of machine learning approaches, with an application for each:\n",
    "\n",
    "| Input (X)           | Output (y)               | Application                 | Type                       |\n",
    "| ------------------- | ------------------------ | --------------------------- | -------------------------- |\n",
    "| email               | spam (0/1)               | Spam filter                 | Classification, supervised |\n",
    "| house details       | house price (numerical)  | Real estate price predictor | Regression, supervised     |\n",
    "| patient data        | disease subtype clusters | Cancer research             | Clustering, unsupervised   |\n",
    "\n",
    "\n",
    "## Sci-Kit Learn\n",
    "\n",
    "When doing any scientific computing in Python, you will eventually come across the Sci Kit Learn library. \n",
    "\n",
    "Sci-Kit Learn is a collection of machine learning algorithms, for both supervised and unsupervised learning. \n",
    "\n",
    "![Scikit-Estimators](./Images/scikit-estimators.png)\n",
    "\n",
    "From the help pages you can see that there are dozens of algorimths implemented in the SciKit Learn library. \n",
    "\n",
    "<https://scikit-learn.org/stable/supervised_learning.html>\n",
    "\n",
    "Most algorithms included in SciKit Learn, where possible, use a common API so that once you have learned to use one algorithm in Sci-Kit Learn, you will have learned them all. \n",
    "\n",
    "## Machine Learning Workflow\n",
    "\n",
    "The basic machine learning workflows is as follows:\n",
    "\n",
    "1. Gather and prepare/clean data\n",
    "2. Train model\n",
    "3. Evaluate model\n",
    "\n",
    "These three phases describe the basic machine learning workflow, and we will cover each of them today. \n",
    "\n",
    "## Gather And Prepare Data\n",
    "\n",
    "A question that is often asked, is how much data do you need? This is a difficult quetion to answer - however, basically this can be thought of in terms of how difficult the problem is to solve. If your dataset regards classifying house prices, based on area of the house, numbers of rooms, and so on, then this might not be a very difficult problem to solve and won't require much data, perhaps 50 or 100 samples. However, if your problem is to predict the effect of some genetic mutation, where the number of features might be in to the 100s, then you might need many thousands of samples before you can train a algorithm. \n",
    "\n",
    "The same can said for image based problems. If your algorithm needs to differentiate between cars and bicycles, then this would require a lot less data than an algorithm that should differentiate between 100 different car models. \n",
    "\n",
    "If you want to use Sci-Kit Learn, it will expect your data to be in a particular format and to follow certain conventions. Luckily, however, once your data is in the format expected by Sci-Kit Learn, almost all of the SciKit Learn's algorithms can be used interchangably, without any modifictions to the data itself or how you have prepared it.\n",
    "\n",
    "So, assuming you have access to some dataset, generally the first thing you will want to do is import and explore the data. \n",
    "\n",
    "There are several tools you could use to do this, however SciKit Learn plays nicely with both NumPy and Pandas (which we saw previously) so we will also use these tools to load in our data and explore the data. \n",
    "\n",
    "If your data is in CSV, Excel or other text-based format then Pandas offers quick and easy functionality to deal with such data. \n",
    "\n",
    "## Skin Disease Dataset\n",
    "\n",
    "To demonstrate things, we will take a look at a skin disease dataset and use Pandas to read the data, explore the data, clean the data, and prepare it for use in SciKit Learn. This is step 1 of the 3 step procedure mentioned above.\n",
    "\n",
    "The dataset in question of erythemato-squamous skin diseases (ESDs), and we will analyze and classify these lesions. To do this, we use a dataset that contains specific observations or features for 366 skin lesions from patients. The features are visual characteristics recorded by a dermatologist, including, for example, \"itching\", \"scaling\", and \"erythema\".\n",
    "\n",
    "![Psoriasis](./Images/psoriasis-edit.jpg)\n",
    "\n",
    "> Image credit:\n",
    "> \n",
    "> Dash, M et al. \"A cascaded deep convolution neural network based CADx system for psoriasis lesion segmentation and severity assessment\". Applied Soft Computing, 91 (2020).\n",
    "\n",
    "Some background regarding the disease:\n",
    "\n",
    "There are six different types of erythemato-squamous diseases, such as psoriasis, which exhibit very similar clinical features and for which signs and symptoms may overlap. A further difficulty in differential diagnosis is that a disease in its early stage may display the features of another disease and only reveal its characteristic features at later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177629f-5ae6-4ae4-b144-035f7f256b12",
   "metadata": {},
   "source": [
    "As already mentioned, the dataset consists of 366 lesions, each with 12 features and a diagnosis. The diagnosis is one of six possible erythemato-squamous diseases.\n",
    "\n",
    "Below is an overview of the individual features in the dataset:\n",
    "\n",
    "| Feature                    | Description                                                     | Values     |\n",
    "| -------------------------- | --------------------------------------------------------------- | ---------- |\n",
    "| Erythema                   | Reddening of the skin caused by increased blood flow            | 0, 1, 2, 3 |\n",
    "| Scaling                    | Scaly or peeling skin surface                                   | 0, 1, 2, 3 |\n",
    "| Definite Borders           | Well-defined borders around skin lesions                        | 0, 1, 2, 3 |\n",
    "| Itching                    | Unpleasant sensation that provokes the urge to scratch          | 0, 1, 2, 3 |\n",
    "| Koebner Phenomenon         | Development of skin lesions at sites of trauma or injury        | 0, 1, 2, 3 |\n",
    "| Polygonal Papules          | Raised, small, polygonal skin papules                           | 0, 1, 2, 3 |\n",
    "| Follicular Papules         | Small papules appearing at hair follicles                       | 0, 1, 2, 3 |\n",
    "| Oral Mucosal Involvement   | Presence of lesions or symptoms in the oral mucosa              | 0, 1, 2, 3 |\n",
    "| Knee and Elbow Involvement | Presence of lesions or symptoms on the knees or elbows          | 0, 1, 2, 3 |\n",
    "| Scalp Involvement          | Involvement of the scalp                                        | 0, 1, 2, 3 |\n",
    "| Family History             | Indicates whether there is a family history of the skin disease | 0, 1       |\n",
    "| Age                        | Linear variable representing the patient’s age                  | Continuous |\n",
    "\n",
    "All features have discrete values from 0 to 3, except for family history, which is binary (true or false), and age, which is continuous.\n",
    "\n",
    "The data were collected through **clinical observation** by a **dermatologist** during patient examination. Most of these features could also be derived from inspection of lesion images (e.g., images acquired with a digital dermatoscope), while others would need to be obtained during patient assessment, such as \"itching\", as well as \"family history\" and \"age\".\n",
    "\n",
    "In addition, each lesion is associated with a **diagnosis**, which is a categorical variable, namely: **Psoriasis**, **Seborrheic Dermatitis**, **Lichen Planus**, **Pityriasis Rosea**, **Chronic Dermatitis**, or **Pityriasis Rubra Pilaris**.\n",
    "\n",
    "The dataset is described in detail in the following work:\n",
    "\n",
    "> Güvenir, H. Altay et al. \"Learning differential diagnosis of erythemato-squamous diseases using voting feature intervals.\" *Artificial Intelligence in Medicine*, 13(3), 1998, 147–165.\n",
    "\n",
    "### Load the Data\n",
    "\n",
    "As mentioned, Pandas has a number of functions for reading and importing various data types. \n",
    "\n",
    "Our skin lesion dataset is in tab-separated values (TSV) format, similar to CSV but using tabs to delimit columns.\n",
    "\n",
    "Before loading it with Pandas, we can preview it within Jupyter itself. Several common file formats can be read directly in Jupyter, although in order to analyse the data we must load it in Python.\n",
    "\n",
    "When looking at a dataset like this, it makes sense to examine the data to check for things like\n",
    "\n",
    "- Inconsistent naming, such as a disease column using different spellings of terms: haemoglobin and hemoglobin or abbreviations are sometimes used and other times not\n",
    "- Missing values, often these appear either as blank or they contain a `?` or `NA` or something similar\n",
    "- Outliers: an age column containing nonsensical numbers (year of birth entered instead of age)\n",
    "\n",
    "What we can notice in our dermatology dataset is that the `age` column does contain some missing values, which have neen substituted for `?` characters.\n",
    "\n",
    "Bearing this in mind, we will use the `read_csv()` function to read the data and store it in `derma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63ffc4-d07f-44c6-bf4b-049b77f2e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "derma = pd.read_csv('dermatology-clinical-only.tsv', sep='\\t', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f16432-557d-433d-8bd4-a39da0f76aec",
   "metadata": {},
   "source": [
    "Notice that we define the seperator as tab using `sep='\\t'` - in the case of a CSV file, this does not need to be defined as by default it is the comma `,` symbol.\n",
    "\n",
    "Also notice, we have instructed Pandas to treat any occurance of a `?` as a missing value, using the `na_values` parameter. When reading the file, Pandas will now give `?` characters a special designation as a missing value. How we deal with these missing values we will see shortly.\n",
    "\n",
    "There are a large number of formats that can be read by Pandas, as you can see if you search for functions beginning with `read_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8274ae-740d-4002-be02-eee0b24fe973",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c5e99-1888-4b71-9255-2e82ea3e9805",
   "metadata": {},
   "source": [
    "In terms of options, there are many ways to configure how you read in your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481da0a8-8272-4e80-a375-08d5793d0878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6cb6d-a077-4015-97be-54d2508c0f99",
   "metadata": {},
   "source": [
    "However, you will notice that generally you will only need to configure one or two of these when loading data. \n",
    "\n",
    "The most commonly use options here are:\n",
    "\n",
    "```python\n",
    "pd.read_csv(\"data.csv\",\n",
    "            sep=\",\",                   # The delimiter to use\n",
    "            header=0,                  # Which row contains your column names, if at all?\n",
    "            index_col=None,            # Which column to use as an index or id\n",
    "            na_values=[\"NA\",\"\", \"?\"])  # How to handle missing data (more on this later)\n",
    "```\n",
    "\n",
    "So, we now have our data, which we stored in `derma` we can preview it. If the dataset is very large, you probably do not want to print the entire contents of the dataset to the screen, therefore two commonly used functions are `head()` and `tail()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d352c-89c8-4f86-9992-1a351e664975",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6651c-709c-4785-8f5b-3c5f203963b0",
   "metadata": {},
   "source": [
    "By default, the first 5 rows are shown but you can change this by passing a different value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b21f4-ed68-4b85-b8ff-300079194e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e13dbd-7295-4b86-b4ce-e358b79ffb61",
   "metadata": {},
   "source": [
    "Also, to preview the end of the dataset, the `tail()` function can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883a647-a9c9-485a-8fbf-d0ee32ce874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5862b-dd62-4ccb-b6c4-b2b2694c9986",
   "metadata": {},
   "source": [
    "Sometimes, there may be too many columns to fit across the screen. In that case, you can either list the columns, this is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644727c-7287-497a-b2c9-a02c12922278",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd1ad2-152f-4e98-b05c-eac0e997cb77",
   "metadata": {},
   "source": [
    "or you could use the transpose function, which basically pivots a table so that the columns are rows and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10d71a-2be8-4458-92cb-87630979ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7329e9-ec07-4b0d-af74-fb4fe5447b89",
   "metadata": {},
   "source": [
    "Some other functions you might want to run when you first load a dataset are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5200f41-2ff5-4163-a3e6-194201085349",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840c648-9952-4b3e-849f-1176cb3ef61d",
   "metadata": {},
   "source": [
    "This tells us the number of rows (samples) and the number of columns in the dataset.\n",
    "\n",
    "The `info()` and `describe()` functions are also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ffc65-7688-4302-8e67-977ce206df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860571d-228f-4946-a16c-30b8ec6964ea",
   "metadata": {},
   "source": [
    "Here we see that `age` has some missing values for example. \n",
    "\n",
    "The `describe()` function can also offer us some insight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4126ef7-0a9d-4563-a7f9-6500c8503b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455975e-360b-40e9-b782-c83b03ac251b",
   "metadata": {},
   "source": [
    "Something else that you might want to do is check the class distribtion of your dataset. For example, in this case, we have a dataset where we have a number of possible diagnoses. One thing you may want to do is to see how many of each class you have in your dataset. This will influence how you might want to analyse the dataset.\n",
    "\n",
    "We can do this quite easily using the `value_counts()` function, which we can apply to the `diagnosis` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccadaaa-0846-4511-9b77-d87dac608cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca9a79-1fc9-4fa6-b428-e4e5355f6d20",
   "metadata": {},
   "source": [
    "Pandas has some simple built in plotting capabilites, so we could plot this using the `plot()` function to see the relative differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedcea4f-c0ed-43c9-92dd-cef35dfe7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma['diagnosis'].value_counts().plot(kind='bar')  # Specify bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a4c8e-21cc-43fa-9537-32efaa3fc63a",
   "metadata": {},
   "source": [
    "What we see here is that psoriasis is the most requent diagnosis. Also pityriasis is very much the minority diagnosis. \n",
    "\n",
    "One quick way to calculate if the distribution might be problematic, is to get the ratio of the largest and smallest classes. If this value is over 5 you may need to alter your training and evaluation strategy.\n",
    "\n",
    "Rule of thumb:\n",
    "\n",
    "- < 2 → balanced\n",
    "- 2-5 → mild/moderate imbalance\n",
    "- \\> 5 → significant imbalance\n",
    "\n",
    "Let's compare the ratio of the most frequent and least frequent diagnoses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb33039-fb1b-4388-81a7-acdc08f86936",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_counts = list(derma.diagnosis.value_counts(sort=True))  # Surround with list() to get a standard Python list back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2fc086-23af-4151-b9ea-aa2fa20c7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c52098-03b7-4ab5-8458-188d0a69af6c",
   "metadata": {},
   "source": [
    "We can use indexing the get the first and last items in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e1699-2500-47f5-bf93-d317889b04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_counts[0] / diag_counts[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a419d-11d7-4b5c-a1da-bc06cc30ec27",
   "metadata": {},
   "source": [
    "The ratio is 5.6, which is borderline according to our rule of thumb above. Values lower than 5 are considered to be acceptable, which a ratio of <2 poses no issues at all.\n",
    "\n",
    "Why would this alter how you analyse your data you might ask?\n",
    "\n",
    "- Training: the model will see many more examples of one class, and very few examples of another class, meaning it will be biased towards diagnosing psoriasis: one possible solution is oversampling\n",
    "- Evaluating: if your test set is dominated by one class, you must be very careful when interpreting results. For example, your test set contains 90% psoriasis samples, and my model predicts always psoriasis, then accuracy will look very good, at 90%, but this is not indicative of the actual performance of the model\n",
    "\n",
    "The value of 5.6 that we have recieved does not mean we cannot use this dataset however. It means we need to be wary of how we approach our analysis.\n",
    "\n",
    "We will discuss these topics a little bit later.\n",
    "\n",
    "### Missing Data\n",
    "\n",
    "Next, we should look to see if we have any missing data in our dataset.\n",
    "\n",
    "This is important because some algorithms cannot handle missing values, and will fail if data is missing. \n",
    "\n",
    "This is such a common task, that Pandas has a built-in function to quickly do this called `is_na()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aba84a-1025-450d-ab5d-881de4d5ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8b197-9434-4f92-9b91-a865e00e4837",
   "metadata": {},
   "source": [
    "According to this, we have 8 missing values in the age column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da0c4f-71aa-4c11-b4e7-607d066bbaa6",
   "metadata": {},
   "source": [
    "If there were multiple columns with missing values, we could sum them with an additional `sum()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acca34-5e55-442a-8084-2d8c902da1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e1433-d495-4fcd-b27a-69fac2b3adc6",
   "metadata": {},
   "source": [
    "However, in our case all our missing data is in the `age` column.\n",
    "\n",
    "In percentage terms, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11b69c-88c9-424c-8a95-d19224c6e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04f36d-0fe1-4c38-ba8c-9311d24e636e",
   "metadata": {},
   "source": [
    "At just over 2%, our dataset is not being impacted by these missing values by a large amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b590f-76b5-4f80-a35e-a38be3dc932c",
   "metadata": {},
   "source": [
    "We can quickly find the rows that contain the missing values as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea847d-9ebc-4193-922c-eff35905b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma[derma.isna().any(axis=1)]  # .any() says to return a row, if any of the values in the row is missing. \n",
    "                                 # The .all() function would return only rows where all values are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a44c92-2536-46c4-91f2-22fc37f14915",
   "metadata": {},
   "source": [
    "As you can see, Pandas has replaced the `?` with `NaN`, meaning 'not a number'. This is an internal data type that represents a missing value. It is not the same as `None` or `Null` which may be a legitmate value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221104e-58a9-49ff-b6de-49294c39bada",
   "metadata": {},
   "source": [
    "**Note**: when loading our dataset, we knew missing values were being written as `?`. If we want to check for other common strings that are used to represent missing data, we can say the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251cadde-63a5-465b-be0a-057557db39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.isin(['', 'NA', 'N/A', 'null', '?']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1f4f5-43e4-4bc6-8228-da647d3c73a5",
   "metadata": {},
   "source": [
    "If others are found here, we could reload the data specifying `NA` as a missing value also, using the `na_values` parameter, **or** we could replace these values with `NaN`:\n",
    "\n",
    "```python\n",
    "derma.replace(['', 'NA', 'N/A', 'null', '?'], np.nan, inplace=True)\n",
    "```\n",
    "\n",
    "### Dealing With Missing Data\n",
    "\n",
    "As mentioned previously, some algorimths cannot handle missing values and require datasets to be complete before they can be analysed.\n",
    "\n",
    "What could we do in the case of our dermatology dataset?\n",
    "\n",
    "We could drop those rows, in fact this is quite commonly done, and we would only lost 2% of our data if we did so. \n",
    "\n",
    "To drop them we'd use the `drop_na()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2842278-9222-4f46-9162-f09f7b923fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ecf049-88ae-4266-9a28-d64db2f68fd7",
   "metadata": {},
   "source": [
    "Notice we have 358 rows. \n",
    "\n",
    "Also notice, the `drop_na()` returns a copy of your dataset, the original is not affected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44fec4-ad89-45b0-982f-fed9aab177cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887880a-2d2b-4d46-855c-860b8e00afaf",
   "metadata": {},
   "source": [
    "So, we still have 366 in our `derma` dataset. Which is good because we do not want to just drop the rows. There are better approaches. \n",
    "\n",
    "For example, for a numerical field such as `age`, we could take the mean or, if appropriate, the median value (for skewed data with outliers), using Pandas' `fillna()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ec89f-a473-4215-bea5-bf9ac6da5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.age.fillna(derma.age.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55639a5c-2315-421d-b3c5-c4eba7509ccd",
   "metadata": {},
   "source": [
    "We need to do this on a column by column basis. \n",
    "\n",
    "**Note**: again, the function has returned a copy of the data (in this case the age column on its own), hence our original data has not been altered. \n",
    "\n",
    "To fix this, we can assign the returned value to itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ba689-95e7-46f0-8f06-a9db1378301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma[\"age\"] = derma[\"age\"].fillna(derma[\"age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc5f71-a30e-4f01-833e-35cbfc18c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78de39d-b1b3-4154-8d03-e4406f943adc",
   "metadata": {},
   "source": [
    "**Note**: mean and median work for numerical values, for categorical values, such as the diagnosis field, you will need to use the **mode**, for example. There are also methods for ordered data, such as backwards or forwards fill, and methods for time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4cb67-0747-48eb-801b-4e208db209f0",
   "metadata": {},
   "source": [
    "We can make a final of all columns check using `isna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1358fa-92ab-45ef-a214-cd63684b10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "derma.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe410a8f-1b58-4936-8b40-368d5fde7de6",
   "metadata": {},
   "source": [
    "### Other Data Preprocessing\n",
    "\n",
    "There are quite a number of things you could do to this data, such as:\n",
    "\n",
    "- Handle missing values\n",
    "- Remove or correct outliers\n",
    "- Normalize/standardize features\n",
    "- Encode categorical variables\n",
    "- Create new features (feature engineering) by combining features\n",
    "- Split data into train/validation/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246f893-42d7-400e-8c09-7825141e8ede",
   "metadata": {},
   "source": [
    "### Preparing Data for SciKit Learn\n",
    "\n",
    "Once your data has been cleaned, we will want to prepare it for SciKit Learn.\n",
    "\n",
    "SciKit Learn expects:\n",
    "\n",
    "- Training data: 2D array, shape `(n_samples, n_features)`\n",
    "- Labels: 1D array, shape `(n_samples,)`\n",
    "\n",
    "Also, it is convention to use `X` for your data and `y` for your labels. A capital `X` is used as it represents a matrix (2D array, tabular data), while `y` is a 1D array (vector) and are conventionally given a lower case letter.\n",
    "\n",
    "Hence we will save our data to `X`, and our labels to `y` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23314e5d-5205-45d3-8d26-b7950dc0e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = derma.drop(columns='diagnosis')\n",
    "y = derma['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615c3d2-85d3-4580-8969-575265e82a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fcb41-964f-4cd2-824c-c7ce6c09c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33479da-14ae-46c9-a8f7-6b5129ccc432",
   "metadata": {},
   "source": [
    "As mentioned above, our data has to have the correct shape, we can check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0589e-1be0-4cbd-b64d-f0a013bb968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d8a64-0b31-44ae-96ca-48931e6ee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ec195-e124-4f95-a3ea-cf6098334f1e",
   "metadata": {},
   "source": [
    "If we take a look at our `y` labels above, we will see that we have the names of the diagnoses as text. Representing our classes as text is not possible with most algorithms, and will only accept numerical classes. \n",
    "\n",
    "Therefore we will represent each diagnosis with a numerical value. What values we give them does not really matter, so we could do something like this:\n",
    "\n",
    "```python\n",
    "derma['diagnosis'] = derma['diagnosis'].replace({\n",
    "    'psoriasis': 1,\n",
    "    'seborrheic dermatitis': 2,\n",
    "    'lichen planus': 3,\n",
    "    'pityriasis rosea': 4,\n",
    "    'chronic dermatitis': 5,\n",
    "    'pityriasis rubra pilaris': 6\n",
    "})\n",
    "```\n",
    "\n",
    "The issue here is that we need to keep track of these values, and to analyse our results later we will need to remember that lichen planus is represented by 3, for example. \n",
    "\n",
    "Luckily Sci-Kit Learn as a label encoder, which encodes our diagnoses numerically, but also can be used to keep track of the association/mapping: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a406ad-71a0-4f2b-9652-8674b3645d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2b739-df74-47f5-8da0-175bb7d3f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9ba6a-9139-4248-bdda-43ba67ddebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a755da-5dd3-4c78-a180-741be6b593e9",
   "metadata": {},
   "source": [
    "If we want to check the mapping, we can do so using the label encoder itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08159d8c-66ea-438d-ab1c-616cecf269fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cafa35-d189-4d03-982d-adb474dbd834",
   "metadata": {},
   "source": [
    "This will save our mapping from the numerical values to the disease names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39c843-2d7b-48d4-966a-28aebaca9d9e",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "The general approach to training a machine learning model is similar for most algorithms.\n",
    "\n",
    "SciKit-Learn's functionality follows a consistent pattern throughout its built-in machine learning algorithms:\n",
    "\n",
    "- Initialize the estimator with some set of parameters\n",
    "- Prepare data using methods such as `train_test_split()`\n",
    "- Fit to training data (using `fit(X, y)`)\n",
    "- Predict on new data (using `predict(X)`) - new data generally being your test set.\n",
    "- Evaluate results with built-in metrics tools, such as `classification_report()` and `confusion_matrix()`\n",
    "\n",
    "This consistent interface makes it easy to swap different algorithms while maintaining the same workflow structure.\n",
    "\n",
    "By convention, training and testing splits are saved as:\n",
    "\n",
    "- `X_train` and `y_train` for your training data and labels\n",
    "- `X_test` and `y_test` for your test data and labels\n",
    "\n",
    "Sci-Kit Learn has a built in train/test split method (`train_test_split()`), which we use now to create our train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719d26e-228a-4aef-8c87-1a04eba11ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4232e-22f9-4ee9-bc6b-4a067bc40802",
   "metadata": {},
   "source": [
    "Now we have our data randomly split in to training data and testing data.\n",
    "\n",
    "**Note** that `train_test_split()` accepts Pandas Data Frames or NumPy arrays.\n",
    "\n",
    "We can preview the data to make sure it has done what we expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce502737-8dd1-4e09-a403-a9a939d3b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3681e568-457c-45f1-bc5d-1b4308255e2c",
   "metadata": {},
   "source": [
    "It is good practice to confirm the sizes of our training and testing data and thei labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b6c35-5f08-477b-81d9-2438e7bd94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952c727-75fc-4b6b-bf05-2d59db8c3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b1495-1e1d-4f27-87a4-5231ea413b8d",
   "metadata": {},
   "source": [
    "Now let's train the random forest algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc86e8-9926-425c-a6bb-a074552cf274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b540f3-6809-4e3e-9b4a-22c0fa9a4e40",
   "metadata": {},
   "source": [
    "Once train, which will only take a few seconds at most, we can get predictions on our **test set**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba887d-b009-4c9d-a187-de3a29e9cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14190a-ee4e-4ecb-8f6a-c1ed63565d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cda2eb-95f0-4ee3-89a5-d5df3002762b",
   "metadata": {},
   "source": [
    "We use the test set so that we give the algorithm data that it has never seen. This simulates a new patient for example. \n",
    "\n",
    "If you pass an algorithm data it has seen before, it means that it has 'seen' the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6826b0-844a-402b-9c2c-d044d0696695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960626ea-b1f0-475b-b5f1-b2583daaf0f5",
   "metadata": {},
   "source": [
    "If you are curious about what features contributed the most to the classifications, many algorithms allow you see these, as they are stored in `model.feature_importances_`, as we see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c301379-87ff-4d6b-ae5f-a5616a0f0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(\n",
    "    forest.feature_importances_,\n",
    "    index=X.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ecd49-66f8-44de-9c76-598b088ab788",
   "metadata": {},
   "source": [
    "The confusion matrix above is the raw output and not really very readible. We can use the saw output above to generate a plot using `ConfusionMatrixDisplay()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960636a-b8fb-4802-9620-76d9605a4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=encoder.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56576b6-3d8a-4598-8104-53fb83492509",
   "metadata": {},
   "source": [
    "The confusion matrix is one of the most important visualisations you can perform to assess model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40143ba-1a22-4ba5-b3da-9d09b6b934c3",
   "metadata": {},
   "source": [
    "### Visualising a Tree\n",
    "\n",
    "Our Random Forest is collection of decision trees: this is called an ensemble.  \n",
    "\n",
    "We can take an individual tree from this forest and visualise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98825b90-2db9-41b6-b23f-a3a7cdd6aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# select one tree from the forest\n",
    "tree = forest.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plot_tree(\n",
    "    tree,\n",
    "    feature_names=X.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    max_depth=2\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b15ae7-648e-448c-8bb5-2af9fbe05c42",
   "metadata": {},
   "source": [
    "As you can see, a tree is a collection of true/fales rules. These rules have been learned during training, based on the data you have given it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681bdda-1338-41d4-aafe-ee7c186f6311",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "In this section we will work on a regression problem, to demonstrate how it differs from classification. \n",
    "\n",
    "Regression differs from clasification in that we are now dealing with a target, $y$, that is a continuous number. This could be house price, heart rate, blood pressure, and so on. They are **not** discrete values like in our classification examples above.\n",
    "\n",
    "Hence, the way we evaluate the regression models is different. We cannot calculate an accuracy, as we do not have discrete classes, and therefore must use other methods of evaluation. \n",
    "\n",
    "The way in which we train and evaluate regression models is also different to classification. \n",
    "\n",
    "To train a regression model, we must use algorithms that are specifically designed to perform regression. In the example below we will use Linear Regression, but there are dozens of different algorithms implemented in SciKit Learn: <https://scikit-learn.org/stable/supervised_learning.html>\n",
    "\n",
    "## House Price Dataset\n",
    "\n",
    "To demonstrate regression we will use a very simple house price dataset that consists of the area of the house and its sale price. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1eca1-e73c-4f2c-b6ca-4df924c14fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price = pd.read_csv('house-price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d7441-742e-425e-8f12-9f22197359ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd12383-7810-4c6b-8687-b0ab5e0aa785",
   "metadata": {},
   "source": [
    "Here we see the size of the house in square feet, and the price of the house in thousands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684c0de-e471-4491-a478-a30792afedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price.plot.scatter(x='sqft', y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3bb96-67cd-4f28-bc5e-9bfb893c0587",
   "metadata": {},
   "source": [
    "As the area of the house increase, as does its price. \n",
    "\n",
    "We will now use Linear Regression to model this relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cadba-41f8-489d-a29a-e05199277bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = house_price.sqft.to_frame()  # to_frame required as Series is not accepted\n",
    "y = house_price.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e16576-2c72-4988-92dc-48358180484b",
   "metadata": {},
   "source": [
    "Now we have trained our linear regression algorithm, we can test it on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bca7b2-49d1-482e-8dfe-fac15b560df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da6f1d-ed7b-4694-b951-0ca7891e6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3aadc-8b74-4762-8013-94b31b5beee0",
   "metadata": {},
   "source": [
    "These are the predicted values for the houses in the test set. We can visualise this a bit better as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754b630-ec30-445c-94b3-1464d0a0674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for area, price in zip(X_test.sqft[:10], y_pred[:10]):\n",
    "    print(f\"Area: {area} sq. ft.\\t Predicted price:\\t{price:.2f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313209d-aa67-475a-af74-33b90cdd0d1a",
   "metadata": {},
   "source": [
    "To evaluate a regression problem, you can measure the difference between the preedicted value and the actual value. This is given by the `score()` function, which is available for regression algorithms only. \n",
    "\n",
    "Conversely, there is no `accuracy_score()` like you would get in a classification model.\n",
    "\n",
    "To compute the score, we can say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657c341-715e-4eb5-b447-cd0d19298e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6891137a-173b-4df9-ae59-6056ef8be6b8",
   "metadata": {},
   "source": [
    "The score returned is known as the $R^2$ score, and it can be interpreted as follows:\n",
    "\n",
    "- $R^2=1.0$: perfect predictions\n",
    "- $R^2=0.0$: no better than predicting the mean of $y$ for every sample\n",
    "\n",
    "The `score()` function gives you a nice value that is easy to quicky understand: the closer to 1 the better. However, it doesn't give you the error which is the difference between the predictions and true values.\n",
    "\n",
    "Therefore, another other metric which is often used is the **mean absolute error**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811252c-abad-4956-ad0f-6f4f081f6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b2d84-5e72-4701-8b54-7148c08f73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4d3b3-1f3a-402b-9388-41c9e0e6fcb3",
   "metadata": {},
   "source": [
    "As you can see, the mean average error is not a value between 0 and 1.0, it shows that the predictions of the model are on average are off by 13.8k. \n",
    "\n",
    "How good or bad this error is depends on the data. If this was a car price predictor, 14k error on average would not be very good. For house prices, 14k error is actually very close.\n",
    "\n",
    "We can visualise this error for each of the data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62706e-20b4-425f-8b1b-a2194ff900ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_test[\"sqft\"], y_test, label=\"Actual\")\n",
    "#plt.scatter(X_test[\"sqft\"], y_pred, label=\"Predicted\")\n",
    "plt.plot(X_test[\"sqft\"], y_pred, color='red', label='Fitted Line')\n",
    "plt.xlabel(\"Square Footage\")\n",
    "plt.ylabel(\"House Price (k)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9113d53-36c4-4e69-95ed-c68530e0689f",
   "metadata": {},
   "source": [
    "The mean absolute error is measuring the average difference between the prediction and the actual price.\n",
    "\n",
    "In this toy example, we only had one feature - square footage - in real world datasets of course we can have many dozens of features. Linear Regression is not limited to just one feature, we simply used this simple dataset so that we could plot the fitted model and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce6e55a-9491-4bd8-a07e-8ffa7a1e8adf",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Perform a regression analysis on a dataset relating to *Abalone*. \n",
    "\n",
    "Abalone are large marine gastropod mollusks (sea snails) in the family *Haliotidae*. They live on rocky coastlines, cling to surfaces with a powerful muscular foot, and graze on algae.\n",
    "\n",
    "The dataset description states:\n",
    "\n",
    "> Predicting the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope - a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.\n",
    "\n",
    "It seems it would be very beneficial if we could predict this age! \n",
    "\n",
    "Here is the code to import the data (we will use a package called `ucimlrepo` to fetch the data from the internet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566a1a6-12e7-4465-a390-554b1e1010b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a5cab-44a7-4885-9565-30f63572de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "abalone = fetch_ucirepo(id=1) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = abalone.data.features \n",
    "y = abalone.data.targets \n",
    "\n",
    "# Remove sex as it is the only non-numeric field\n",
    "# and it makes the analysis much easier later\n",
    "X = X.drop('Sex', axis=1)\n",
    "\n",
    "# variable information \n",
    "print(abalone.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd627c-c423-4a2b-b26c-b8c843eb19bd",
   "metadata": {},
   "source": [
    "We can preview the data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f7063-b37a-4ec5-9736-9716137319c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db3439-ff56-44da-8961-a21ef38444c8",
   "metadata": {},
   "source": [
    "And preview the target `y` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe5a6d-1854-468f-b1aa-38acadd64f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808801d-ef04-4f8b-a0ed-3b7af8402eaf",
   "metadata": {},
   "source": [
    "Print the number of columns and rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6f0f4-5392-4531-a3c0-fec6e8de309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X has {X.shape[0]} rows and {X.shape[1]} columns/features.\")\n",
    "print(f\"y has {y.shape[0]} rows and {y.shape[1]} column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30984ac6-c0a5-4335-8504-e64c5f5380e9",
   "metadata": {},
   "source": [
    "We now have our data as Pandas Data Frames. Our data is stored in `X` and our labels are stored in `y`.\n",
    "\n",
    "Now create a train test split of 70% training data and 30% testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed3258-a84e-4b31-a8ab-b558b3c8eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6552c-cbde-4e0b-97ab-1e596cc5722a",
   "metadata": {},
   "source": [
    "Now train a Decision Tree Regressor algorithm, see <https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor>\n",
    "\n",
    "Use default paramaters, except for max depth, which you should change to 3 (the parameter is named `max_depth`, so set `max_depth=3`).\n",
    "\n",
    "**Important**: Store your decision tree regressor in a variable named `tree`.\n",
    "\n",
    "The import has been provided for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f39320-a62d-44f7-96fa-d4827aa0cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Code here\n",
    "tree = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9e7ce-ad2f-4e31-b112-d4e1eed233ad",
   "metadata": {},
   "source": [
    "Now that you have trained the tree, make your predictions and store them in `y_pred` as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74dc0af-c343-4dc1-b62a-daf77a467dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "\n",
    "y_pred = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cbcc7-d398-4348-9181-a43e6ee815a8",
   "metadata": {},
   "source": [
    "Calculate the mean absolute eror of your method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f38eb-2261-46ba-bbc8-83a9e2890617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276edce1-8574-4544-b1d3-4182b9593c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26046a-f37c-4abe-a6de-a5fe61c4b723",
   "metadata": {},
   "source": [
    "Interpret this result, in written words:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4114a4-ef3b-435d-8a64-85be7c0758a8",
   "metadata": {},
   "source": [
    "\n",
    "This is the average difference in ages in years, between the predictions and the true age. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b88de-ec7c-4d3b-b5cf-b5ecefa40aee",
   "metadata": {},
   "source": [
    "Show the feature importances (code above can be used almost verbatim):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2276c-f581-476e-b94a-8edca16fc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07168204-df07-41da-87ed-1676ad931092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "importances = pd.Series(\n",
    "    tree.feature_importances_,\n",
    "    index=X.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d13a4-9ba7-4d39-bea7-8895d135968c",
   "metadata": {},
   "source": [
    "Interpret this in plain English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a3b4f-ae95-4079-90c0-008ef8fc130e",
   "metadata": {},
   "source": [
    "The shell weight has the strongest correlation to age.\n",
    "\n",
    "OR: The largest contribution to age is the weight of the shell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a4f3b-e77f-4ea1-8a94-c3d9f60bf649",
   "metadata": {},
   "source": [
    "If you have written all the code as specified, then the following should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d20ac6-ff6c-4466-82be-4281ca04d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plot_tree(\n",
    "    tree,\n",
    "    feature_names=X.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    max_depth=3\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32abff-03f9-4817-8a55-43e7a3e651e0",
   "metadata": {},
   "source": [
    "\n",
    "The tree has learned a set of yes/no rules that can be used to predict the age of an abalone. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177b3c2-b4f5-4085-8ff2-bb80a184a222",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Unsupervised Learning\n",
    "\n",
    "Unsupervised learning is for data where you have no target variable. \n",
    "\n",
    "It is used far less frequently than supervised learned, and is mainly used for exploratory analysis of data. Typically unsupervised algorithms tend to cluster data in to groups, where more similar items tend to cluster together. This is done by trying to find sammples which have characteristics in common, and clustering these. \n",
    "\n",
    "## Clustering\n",
    "\n",
    "One of the most simple methods is called $k$-means clustering. \n",
    "\n",
    "## Wisconsin Breast Cancer Dataset\n",
    "\n",
    "SciKit learn has a number of built-in datasets, including the breast cancer dataset we will analyse now.\n",
    "\n",
    "> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\n",
    "\n",
    "It contains the followng features:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry\n",
    "- fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "Also: \n",
    "\n",
    "- Target: Diagnosis (M = malignant, B = benign)\n",
    "- Class distribution: 357 benign, 212 malignant\n",
    "\n",
    "We will not be using the diagnosis target during training however! The $k$-means algorithm is an unsupervised learning algorithm and does not use the target variable to train!\n",
    "\n",
    "First load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04372c57-c793-45ce-9cc9-3a823997442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data          # features\n",
    "y = data.target        # true labels (0 = malignant, 1 = benign)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab603ce-3282-4d45-80c2-3955976f2e11",
   "metadata": {},
   "source": [
    "We now have our data in the customary `X` and `y` data structures.\n",
    "\n",
    "Notice that we use the `sklearn.datasets` module. \n",
    "\n",
    "This module contains a number of datasets that you can load straight in to SciKit Learn, which have already been prepared in the format that SciKit-Learn expects. \n",
    "\n",
    "See <https://scikit-learn.org/stable/datasets.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357893e1-b875-4a97-be7a-313474951d01",
   "metadata": {},
   "source": [
    "We can preview the data, but we shall it is not particularly interpretable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e2ab8-b77f-4d37-ab4e-2ba42a3be4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb34354-7580-441a-8e20-257143616c7a",
   "metadata": {},
   "source": [
    "Now we define our clustering algorithm, stating that we want 2 clusters. Note, that in this case we know that there are two groups, but in a real-world clustering scenario, you might not know this and would need to experiment with the number of clusters.\n",
    "\n",
    "So, let's define the algorithm and fit it to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fad43e-ae2f-4471-9d20-d85c4c9fb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee95e3b-6e59-474b-84bc-3a8fc3133ff8",
   "metadata": {},
   "source": [
    "The algorithm will now have assigned each sample to either cluster 1 or 2. \n",
    "\n",
    "Because we do actually have the true labels, we can map each prediction to a class, so that cluster 1 is considered a classification to benign and cluster 2 is considered a classification to malignant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd51f50-0fb3-46b0-aaf0-2010ef7da9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def remap_clusters(true_labels, cluster_labels):\n",
    "    new_labels = np.zeros_like(cluster_labels)\n",
    "    for c in np.unique(cluster_labels):\n",
    "        mask = cluster_labels == c\n",
    "        new_labels[mask] = mode(true_labels[mask], keepdims=True).mode[0]\n",
    "    return new_labels\n",
    "\n",
    "clusters_aligned = remap_clusters(y, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24706160-07d1-4de2-8aac-9b5408493f88",
   "metadata": {},
   "source": [
    "We can print our metrics as we did for the classification algorithm earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ad895-22c7-4043-999a-a37630b7bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y, clusters_aligned))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y, clusters_aligned))\n",
    "\n",
    "print(classification_report(y, clusters_aligned, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7e059-390f-490d-90b3-8d3f95cc7228",
   "metadata": {},
   "source": [
    "And we can plot the clustering by first reducing the dimensionality to 2 using PCA, and then plotting these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4176a-6a0b-43a7-ae76-29950c9840a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, s=20)\n",
    "plt.title(\"K-Means Clustering (PCA projection)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654e749-70e5-47be-bdf1-cbb16d373fce",
   "metadata": {},
   "source": [
    "Now that you have two groups, you can try to fit a line to seperate the groups, and use this line as a final classifier for any new data. \n",
    "\n",
    "Becuase unsupervised learning is not as common as supervised learning, we have not discussed it in much detail here. However it is worth knowing that technqiues such as clustering exist for exploratory analysis of your data, in the situation where you have no target variable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e95a0-b247-474f-a29b-c0f61c524828",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "© 2026, Marcus D. Bloice, licensed under <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY-SA 4.0</a><img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\" alt=\"\" style=\"max-width: 1em;max-height:1em;margin-left: .2em;\"><img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\" alt=\"\" style=\"max-width: 1em;max-height:1em;margin-left: .2em;\"><img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg\" alt=\"\" style=\"max-width: 1em;max-height:1em;margin-left: .2em;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
